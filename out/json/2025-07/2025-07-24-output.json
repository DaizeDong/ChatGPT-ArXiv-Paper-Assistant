{
    "2507.17343": {
        "SCORE": 17,
        "ARXIVID": "2507.17343",
        "COMMENT": "The paper proposes a novel framework for multimodal representation learning, addressing challenges in simultaneous alignment of multiple modalities, which aligns with representation learning.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Xiaohao Liu",
            "Xiaobo Xia",
            "See-Kiong Ng",
            "Tat-Seng Chua"
        ],
        "title": "Principled Multimodal Representation Learning",
        "abstract": "Multimodal representation learning seeks to create a unified representation space by integrating diverse data modalities to improve multimodal understanding. Traditional methods often depend on pairwise contrastive learning, which relies on a predefined anchor modality, restricting alignment across all modalities. Recent advances have investigated the simultaneous alignment of multiple modalities, yet several challenges remain, such as limitations imposed by fixed anchor points and instability arising from optimizing the product of singular values. To address the challenges, in this paper, we propose Principled Multimodal Representation Learning (PMRL), a novel framework that achieves simultaneous alignment of multiple modalities without anchor dependency in a more stable manner. Specifically, grounded in the theoretical insight that full alignment corresponds to a rank-1 Gram matrix, PMRL optimizes the dominant singular value of the representation matrix to align modalities along a shared leading direction. We propose a softmax-based loss function that treats singular values as logits to prioritize the largest singular value. Besides, instance-wise contrastive regularization on the leading eigenvectors maintains inter-instance separability and prevents representation collapse. Extensive experiments across diverse tasks demonstrate PMRL's superiority compared to baseline methods. The source code will be publicly available.",
        "arxiv_id": "2507.17343"
    },
    "2507.16871": {
        "SCORE": 17,
        "ARXIVID": "2507.16871",
        "COMMENT": "The paper expands on the mathematical structures of Cartan Neural Networks, providing insights into their geometric properties, which aligns with emerging trends in theoretical work.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Pietro Giuseppe Fr\\'e",
            "Federico Milanesio",
            "Guido Sanguinetti",
            "Matteo Santoro"
        ],
        "title": "Navigation through Non-Compact Symmetric Spaces: a mathematical perspective on Cartan Neural Networks",
        "abstract": "Recent work has identified non-compact symmetric spaces U/H as a promising class of homogeneous manifolds to develop a geometrically consistent theory of neural networks. An initial implementation of these concepts has been presented in a twin paper under the moniker of Cartan Neural Networks, showing both the feasibility and the performance of these geometric concepts in a machine learning context. The current paper expands on the mathematical structures underpinning Cartan Neural Networks, detailing the geometric properties of the layers and how the maps between layers interact with such structures to make Cartan Neural Networks covariant and geometrically interpretable. Together, these twin papers constitute a first step towards a fully geometrically interpretable theory of neural networks exploiting group-theoretic structures",
        "arxiv_id": "2507.16871"
    },
    "2507.16933": {
        "SCORE": 17,
        "ARXIVID": "2507.16933",
        "COMMENT": "The paper presents a quantization-aware training approach for large language models, which is relevant to model compression and efficiency.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Steven K. Esser",
            "Jeffrey L. McKinstry",
            "Deepika Bablani",
            "Rathinakumar Appuswamy",
            "Dharmendra S. Modha"
        ],
        "title": "SiLQ: Simple Large Language Model Quantization-Aware Training",
        "abstract": "Large language models can be quantized to reduce inference time latency, model size, and energy consumption, thereby delivering a better user experience at lower cost. A challenge exists to deliver quantized models with minimal loss of accuracy in reasonable time, and in particular to do so without requiring mechanisms incompatible with specialized inference accelerators. Here, we demonstrate a simple, end-to-end quantization-aware training approach that, with an increase in total model training budget of less than 0.1%, outperforms the leading published quantization methods by large margins on several modern benchmarks, with both base and instruct model variants. The approach easily generalizes across different model architectures, can be applied to activations, cache, and weights, and requires the introduction of no additional operations to the model other than the quantization itself.",
        "arxiv_id": "2507.16933"
    },
    "2507.17221": {
        "SCORE": 17,
        "ARXIVID": "2507.17221",
        "COMMENT": "The paper proposes a joint rate-utility optimization method for dataset distillation, relevant to model compression and efficiency.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Youneng Bao",
            "Yiping Liu",
            "Zhuo Chen",
            "Yongsheng Liang",
            "Mu Li",
            "Kede Ma"
        ],
        "title": "Dataset Distillation as Data Compression: A Rate-Utility Perspective",
        "abstract": "Driven by the ``scale-is-everything'' paradigm, modern machine learning increasingly demands ever-larger datasets and models, yielding prohibitive computational and storage requirements. Dataset distillation mitigates this by compressing an original dataset into a small set of synthetic samples, while preserving its full utility. Yet, existing methods either maximize performance under fixed storage budgets or pursue suitable synthetic data representations for redundancy removal, without jointly optimizing both objectives. In this work, we propose a joint rate-utility optimization method for dataset distillation. We parameterize synthetic samples as optimizable latent codes decoded by extremely lightweight networks. We estimate the Shannon entropy of quantized latents as the rate measure and plug any existing distillation loss as the utility measure, trading them off via a Lagrange multiplier. To enable fair, cross-method comparisons, we introduce bits per class (bpc), a precise storage metric that accounts for sample, label, and decoder parameter costs. On CIFAR-10, CIFAR-100, and ImageNet-128, our method achieves up to $170\\times$ greater compression than standard distillation at comparable accuracy. Across diverse bpc budgets, distillation losses, and backbone architectures, our approach consistently establishes better rate-utility trade-offs.",
        "arxiv_id": "2507.17221"
    },
    "2507.16872": {
        "SCORE": 16,
        "ARXIVID": "2507.16872",
        "COMMENT": "The paper discusses model compression techniques like pruning and quantization, which are relevant to model compression and efficiency breakthroughs.",
        "RELEVANCE": 9,
        "NOVELTY": 7,
        "authors": [
            "Na Li",
            "Yansong Gao",
            "Hongsheng Hu",
            "Boyu Kuang",
            "Anmin Fu"
        ],
        "title": "CompLeak: Deep Learning Model Compression Exacerbates Privacy Leakage",
        "abstract": "Model compression is crucial for minimizing memory storage and accelerating inference in deep learning (DL) models, including recent foundation models like large language models (LLMs). Users can access different compressed model versions according to their resources and budget. However, while existing compression operations primarily focus on optimizing the trade-off between resource efficiency and model performance, the privacy risks introduced by compression remain overlooked and insufficiently understood.   In this work, through the lens of membership inference attack (MIA), we propose CompLeak, the first privacy risk evaluation framework examining three widely used compression configurations that are pruning, quantization, and weight clustering supported by the commercial model compression framework of Google's TensorFlow-Lite (TF-Lite) and Facebook's PyTorch Mobile. CompLeak has three variants, given available access to the number of compressed models and original model. CompLeakNR starts by adopting existing MIA methods to attack a single compressed model, and identifies that different compressed models influence members and non-members differently. When the original model and one compressed model are available, CompLeakSR leverages the compressed model as a reference to the original model and uncovers more privacy by combining meta information (e.g., confidence vector) from both models. When multiple compressed models are available with/without accessing the original model, CompLeakMR innovatively exploits privacy leakage info from multiple compressed versions to substantially signify the overall privacy leakage. We conduct extensive experiments on seven diverse model architectures (from ResNet to foundation models of BERT and GPT-2), and six image and textual benchmark datasets.",
        "arxiv_id": "2507.16872"
    },
    "2507.17001": {
        "SCORE": 16,
        "ARXIVID": "2507.17001",
        "COMMENT": "The paper presents a framework that leverages data bias for out-of-distribution generation, providing theoretical insights, which aligns with emerging trends in challenging established assumptions.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Yan Li",
            "Guangyi Chen",
            "Yunlong Deng",
            "Zijian Li",
            "Zeyu Tang",
            "Anpeng Wu",
            "Kun Zhang"
        ],
        "title": "Should Bias Always be Eliminated? A Principled Framework to Use Data Bias for OOD Generation",
        "abstract": "Most existing methods for adapting models to out-of-distribution (OOD) domains rely on invariant representation learning to eliminate the influence of biased features. However, should bias always be eliminated -- and if not, when should it be retained, and how can it be leveraged? To address these questions, we first present a theoretical analysis that explores the conditions under which biased features can be identified and effectively utilized. Building on this theoretical foundation, we introduce a novel framework that strategically leverages bias to complement invariant representations during inference. The framework comprises two key components that leverage bias in both direct and indirect ways: (1) using invariance as guidance to extract predictive ingredients from bias, and (2) exploiting identified bias to estimate the environmental condition and then use it to explore appropriate bias-aware predictors to alleviate environment gaps. We validate our approach through experiments on both synthetic datasets and standard domain generalization benchmarks. Results consistently demonstrate that our method outperforms existing approaches, underscoring its robustness and adaptability.",
        "arxiv_id": "2507.17001"
    },
    "2507.17725": {
        "SCORE": 16,
        "ARXIVID": "2507.17725",
        "COMMENT": "The paper explores the interaction between compressibility and adversarial robustness, providing insights into representation learning and model compression.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Melih Barsbey",
            "Ant\\^onio H. Ribeiro",
            "Umut \\c{S}im\\c{s}ekli",
            "Tolga Birdal"
        ],
        "title": "On the Interaction of Compressibility and Adversarial Robustness",
        "abstract": "Modern neural networks are expected to simultaneously satisfy a host of desirable properties: accurate fitting to training data, generalization to unseen inputs, parameter and computational efficiency, and robustness to adversarial perturbations. While compressibility and robustness have each been studied extensively, a unified understanding of their interaction still remains elusive. In this work, we develop a principled framework to analyze how different forms of compressibility - such as neuron-level sparsity and spectral compressibility - affect adversarial robustness. We show that these forms of compression can induce a small number of highly sensitive directions in the representation space, which adversaries can exploit to construct effective perturbations. Our analysis yields a simple yet instructive robustness bound, revealing how neuron and spectral compressibility impact $L_\\infty$ and $L_2$ robustness via their effects on the learned representations. Crucially, the vulnerabilities we identify arise irrespective of how compression is achieved - whether via regularization, architectural bias, or implicit learning dynamics. Through empirical evaluations across synthetic and realistic tasks, we confirm our theoretical predictions, and further demonstrate that these vulnerabilities persist under adversarial training and transfer learning, and contribute to the emergence of universal adversarial perturbations. Our findings show a fundamental tension between structured compressibility and robustness, and suggest new pathways for designing models that are both efficient and secure.",
        "arxiv_id": "2507.17725"
    },
    "2507.17470": {
        "SCORE": 16,
        "ARXIVID": "2507.17470",
        "COMMENT": "The paper introduces predictive surrogates for quantum processors, which is relevant to AI for Science with a focus on foundational research in quantum modeling.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Wei-You Liao",
            "Yuxuan Du",
            "Xinbiao Wang",
            "Tian-Ci Tian",
            "Yong Luo",
            "Bo Du",
            "Dacheng Tao",
            "He-Liang Huang"
        ],
        "title": "Demonstration of Efficient Predictive Surrogates for Large-scale Quantum Processors",
        "abstract": "The ongoing development of quantum processors is driving breakthroughs in scientific discovery. Despite this progress, the formidable cost of fabricating large-scale quantum processors means they will remain rare for the foreseeable future, limiting their widespread application. To address this bottleneck, we introduce the concept of predictive surrogates, which are classical learning models designed to emulate the mean-value behavior of a given quantum processor with provably computational efficiency. In particular, we propose two predictive surrogates that can substantially reduce the need for quantum processor access in diverse practical scenarios. To demonstrate their potential in advancing digital quantum simulation, we use these surrogates to emulate a quantum processor with up to 20 programmable superconducting qubits, enabling efficient pre-training of variational quantum eigensolvers for families of transverse-field Ising models and identification of non-equilibrium Floquet symmetry-protected topological phases. Experimental results reveal that the predictive surrogates not only reduce measurement overhead by orders of magnitude, but can also surpass the performance of conventional, quantum-resource-intensive approaches. Collectively, these findings establish predictive surrogates as a practical pathway to broadening the impact of advanced quantum processors.",
        "arxiv_id": "2507.17470"
    },
    "2507.17662": {
        "SCORE": 15,
        "ARXIVID": "2507.17662",
        "COMMENT": "The paper introduces a novel architecture combining state-space models, transformers, and a sequential mixture of experts, which aligns with model architecture innovations.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Farnoush Bayatmakou",
            "Reza Taleei",
            "Nicole Simone",
            "Arash Mohammadi"
        ],
        "title": "Mammo-Mamba: A Hybrid State-Space and Transformer Architecture with Sequential Mixture of Experts for Multi-View Mammography",
        "abstract": "Breast cancer (BC) remains one of the leading causes of cancer-related mortality among women, despite recent advances in Computer-Aided Diagnosis (CAD) systems. Accurate and efficient interpretation of multi-view mammograms is essential for early detection, driving a surge of interest in Artificial Intelligence (AI)-powered CAD models. While state-of-the-art multi-view mammogram classification models are largely based on Transformer architectures, their computational complexity scales quadratically with the number of image patches, highlighting the need for more efficient alternatives. To address this challenge, we propose Mammo-Mamba, a novel framework that integrates Selective State-Space Models (SSMs), transformer-based attention, and expert-driven feature refinement into a unified architecture. Mammo-Mamba extends the MambaVision backbone by introducing the Sequential Mixture of Experts (SeqMoE) mechanism through its customized SecMamba block. The SecMamba is a modified MambaVision block that enhances representation learning in high-resolution mammographic images by enabling content-adaptive feature refinement. These blocks are integrated into the deeper stages of MambaVision, allowing the model to progressively adjust feature emphasis through dynamic expert gating, effectively mitigating the limitations of traditional Transformer models. Evaluated on the CBIS-DDSM benchmark dataset, Mammo-Mamba achieves superior classification performance across all key metrics while maintaining computational efficiency.",
        "arxiv_id": "2507.17662"
    },
    "2507.16836": {
        "SCORE": 15,
        "ARXIVID": "2507.16836",
        "COMMENT": "The paper applies sparse autoencoders to interpret speech models for Parkinson's disease, aligning with representation learning and sparse methods.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Peter Plantinga",
            "Jen-Kai Chen",
            "Roozbeh Sattari",
            "Mirco Ravanelli",
            "Denise Klein"
        ],
        "title": "From Black Box to Biomarker: Sparse Autoencoders for Interpreting Speech Models of Parkinson's Disease",
        "abstract": "Speech holds promise as a cost-effective and non-invasive biomarker for neurological conditions such as Parkinson's disease (PD). While deep learning systems trained on raw audio can find subtle signals not available from hand-crafted features, their black-box nature hinders clinical adoption. To address this, we apply sparse autoencoders (SAEs) to uncover interpretable internal representations from a speech-based PD detection system. We introduce a novel mask-based activation for adapting SAEs to small biomedical datasets, creating sparse disentangled dictionary representations. These dictionary entries are found to have strong associations with characteristic articulatory deficits in PD speech, such as reduced spectral flux and increased spectral flatness in the low-energy regions highlighted by the model attention. We further show that the spectral flux is related to volumetric measurements of the putamen from MRI scans, demonstrating the potential of SAEs to reveal clinically relevant biomarkers for disease monitoring and diagnosis.",
        "arxiv_id": "2507.16836"
    },
    "2507.17748": {
        "SCORE": 15,
        "ARXIVID": "2507.17748",
        "COMMENT": "The paper discusses how large learning rates can achieve robustness and compressibility, providing insights into representation learning and model efficiency.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Melih Barsbey",
            "Lucas Prieto",
            "Stefanos Zafeiriou",
            "Tolga Birdal"
        ],
        "title": "Large Learning Rates Simultaneously Achieve Robustness to Spurious Correlations and Compressibility",
        "abstract": "Robustness and resource-efficiency are two highly desirable properties for modern machine learning models. However, achieving them jointly remains a challenge. In this paper, we position high learning rates as a facilitator for simultaneously achieving robustness to spurious correlations and network compressibility. We demonstrate that large learning rates also produce desirable representation properties such as invariant feature utilization, class separation, and activation sparsity. Importantly, our findings indicate that large learning rates compare favorably to other hyperparameters and regularization methods, in consistently satisfying these properties in tandem. In addition to demonstrating the positive effect of large learning rates across diverse spurious correlation datasets, models, and optimizers, we also present strong evidence that the previously documented success of large learning rates in standard classification tasks is likely due to its effect on addressing hidden/rare spurious correlations in the training dataset.",
        "arxiv_id": "2507.17748"
    },
    "2507.17501": {
        "SCORE": 15,
        "ARXIVID": "2507.17501",
        "COMMENT": "The paper introduces a new Transformer variant, DNT, which can be trained with momentum SGD, aligning with the model architecture criterion.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Xianbiao Qi",
            "Marco Chen",
            "Wenjie Xiao",
            "Jiaquan Ye",
            "Yelin He",
            "Chun-Guang Li",
            "Zhouchen Lin"
        ],
        "title": "DNT: a Deeply Normalized Transformer that can be trained by Momentum SGD",
        "abstract": "Transformers have become the de facto backbone of modern deep learning, yet their training typically demands an advanced optimizer with adaptive learning rate like AdamW, rather than a momentum SGDW (mSGDW). Previous works show that it is mainly due to a heavy-tailed distribution of the gradients. In this paper, we introduce a Deeply Normalized Transformer (DNT), which is meticulously engineered to overcome this limitation enabling seamless training with vanilla mSGDW while yielding comparable performance to the Transformers trained via AdamW. To be specific, in DNT, we strategically integrate normalization techniques at proper positions in the Transformers to effectively modulate the Jacobian matrices of each layer, balance the influence of weights, activations, and their interactions, and thus enable the distributions of gradients concentrated. We provide both theoretical justifications of the normalization technique used in our DNT and extensive empirical evaluation on two popular Transformer architectures to validate that: a) DNT outperforms its counterparts (\\ie, ViT and GPT), and b) DNT can be effectively trained with vanilla mSGDW.",
        "arxiv_id": "2507.17501"
    },
    "2507.17168": {
        "SCORE": 15,
        "ARXIVID": "2507.17168",
        "COMMENT": "The paper introduces a new approach to enhance LLMs' reasoning abilities using graph problems, which aligns with the large language models criterion.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Qifan Zhang",
            "Nuo Chen",
            "Zehua Li",
            "Miao Peng",
            "Jing Tang",
            "Jia Li"
        ],
        "title": "Improving LLMs' Generalized Reasoning Abilities by Graph Problems",
        "abstract": "Large Language Models (LLMs) have made remarkable strides in reasoning tasks, yet their performance often falters on novel and complex problems. Domain-specific continued pretraining (CPT) methods, such as those tailored for mathematical reasoning, have shown promise but lack transferability to broader reasoning tasks. In this work, we pioneer the use of Graph Problem Reasoning (GPR) to enhance the general reasoning capabilities of LLMs. GPR tasks, spanning pathfinding, network analysis, numerical computation, and topological reasoning, require sophisticated logical and relational reasoning, making them ideal for teaching diverse reasoning patterns. To achieve this, we introduce GraphPile, the first large-scale corpus specifically designed for CPT using GPR data. Spanning 10.9 billion tokens across 23 graph tasks, the dataset includes chain-of-thought, program-of-thought, trace of execution, and real-world graph data. Using GraphPile, we train GraphMind on popular base models Llama 3 and 3.1, as well as Gemma 2, achieving up to 4.9 percent higher accuracy in mathematical reasoning and up to 21.2 percent improvement in non-mathematical reasoning tasks such as logical and commonsense reasoning. By being the first to harness GPR for enhancing reasoning patterns and introducing the first dataset of its kind, our work bridges the gap between domain-specific pretraining and universal reasoning capabilities, advancing the adaptability and robustness of LLMs.",
        "arxiv_id": "2507.17168"
    },
    "2507.17706": {
        "SCORE": 15,
        "ARXIVID": "2507.17706",
        "COMMENT": "The paper introduces a new model merging technique, HydraOpt, which is relevant to model compression through low-rank approaches.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Taha Ceritli",
            "Ondrej Bohdal",
            "Mete Ozay",
            "Jijoong Moon",
            "Kyeng-Hun Lee",
            "Hyeonmok Ko",
            "Umberto Michieli"
        ],
        "title": "HydraOpt: Navigating the Efficiency-Performance Trade-off of Adapter Merging",
        "abstract": "Large language models (LLMs) often leverage adapters, such as low-rank-based adapters, to achieve strong performance on downstream tasks. However, storing a separate adapter for each task significantly increases memory requirements, posing a challenge for resource-constrained environments such as mobile devices. Although model merging techniques can reduce storage costs, they typically result in substantial performance degradation. In this work, we introduce HydraOpt, a new model merging technique that capitalizes on the inherent similarities between the matrices of low-rank adapters. Unlike existing methods that produce a fixed trade-off between storage size and performance, HydraOpt allows us to navigate this spectrum of efficiency and performance. Our experiments show that HydraOpt significantly reduces storage size (48% reduction) compared to storing all adapters, while achieving competitive performance (0.2-1.8% drop). Furthermore, it outperforms existing merging techniques in terms of performance at the same or slightly worse storage efficiency.",
        "arxiv_id": "2507.17706"
    },
    "2507.17454": {
        "SCORE": 15,
        "ARXIVID": "2507.17454",
        "COMMENT": "The paper introduces a novel representation learning framework combining channel-mixing and channel-independence strategies, relevant to representation learning.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Shusen Ma",
            "Yun-Bo Zhao",
            "Yu Kang"
        ],
        "title": "C3RL: Rethinking the Combination of Channel-independence and Channel-mixing from Representation Learning",
        "abstract": "Multivariate time series forecasting has drawn increasing attention due to its practical importance. Existing approaches typically adopt either channel-mixing (CM) or channel-independence (CI) strategies. CM strategy can capture inter-variable dependencies but fails to discern variable-specific temporal patterns. CI strategy improves this aspect but fails to fully exploit cross-variable dependencies like CM. Hybrid strategies based on feature fusion offer limited generalization and interpretability. To address these issues, we propose C3RL, a novel representation learning framework that jointly models both CM and CI strategies. Motivated by contrastive learning in computer vision, C3RL treats the inputs of the two strategies as transposed views and builds a siamese network architecture: one strategy serves as the backbone, while the other complements it. By jointly optimizing contrastive and prediction losses with adaptive weighting, C3RL balances representation and forecasting performance. Extensive experiments on seven models show that C3RL boosts the best-case performance rate to 81.4\\% for models based on CI strategy and to 76.3\\% for models based on CM strategy, demonstrating strong generalization and effectiveness. The code will be available once the paper is accepted.",
        "arxiv_id": "2507.17454"
    }
}