[SELECTION]
# author matching
run_author_match = true
author_match_score = 20

# gpt matching
run_openai = true
#model = gpt-4o-mini
model = gpt-4o

# cost quality tradeoff - larger batches are cheaper but less accurate.
title_batch_size = 8
abstract_batch_size = 4
# whether to adjust the batch size according to the number of papers.
# If true, the batch size will scale logarithmically with the number of papers by `adaptive_threshold`.
# For example, if `batch_size=1` and `adaptive_threshold=10`, the real batch size will be: 1 for <=10 papers, 2 for 11-20 papers, 3 for 21-40 papers, 4 for 41-80 papers, etc.
adaptive_batch_size = true
adaptive_threshold = 32

[FILTERING]
# https://arxiv.org/category_taxonomy
arxiv_category = cs.LG,cs.AI
# type of papers on arxiv to preserve: new, cross, replace, replace-cross. Details in https://info.arxiv.org/help/rss_specifications.html
announce_type = new,cross
# force_primary ignores papers that are only cross-listed into the arxiv_category
force_primary = false
# (deprecated?) draws num_samples samples from the LM and averages scores
num_samples = 1
# Filter out any papers that have no authors with h-index above `h_cutoff`
h_cutoff = 12
relevance_cutoff = 7
novelty_cutoff = 6

[OUTPUT]
debug_messages = false
output_path = out/
dump_debug_file = false
dump_json = true
dump_md = true
push_to_slack = false