{
    "2501.14441": {
        "authors": [
            "Hermanus L. Potgieter",
            "Coenraad Mouton",
            "Marelie H. Davel"
        ],
        "title": "Impact of Batch Normalization on Convolutional Network Representations",
        "abstract": "Batch normalization (BatchNorm) is a popular layer normalization technique used when training deep neural networks. It has been shown to enhance the training speed and accuracy of deep learning models. However, the mechanics by which BatchNorm achieves these benefits is an active area of research, and different perspectives have been proposed. In this paper, we investigate the effect of BatchNorm on the resulting hidden representations, that is, the vectors of activation values formed as samples are processed at each hidden layer. Specifically, we consider the sparsity of these representations, as well as their implicit clustering -- the creation of groups of representations that are similar to some extent. We contrast image classification models trained with and without batch normalization and highlight consistent differences observed. These findings highlight that BatchNorm's effect on representational sparsity is not a significant factor affecting generalization, while the representations of models trained with BatchNorm tend to show more advantageous clustering characteristics.",
        "arxiv_id": "2501.14441",
        "ARXIVID": "2501.14441",
        "COMMENT": "This paper examines how BatchNorm affects representational sparsity and implicit clustering, falling squarely under representation learning. The insights about BatchNorm's influence on hidden representations are conceptually valuable.",
        "RELEVANCE": 9,
        "NOVELTY": 8
    },
    "2501.13982": {
        "authors": [
            "Chengyi Cai",
            "Zesheng Ye",
            "Lei Feng",
            "Jianzhong Qi",
            "Feng Liu"
        ],
        "title": "Attribute-based Visual Reprogramming for Image Classification with CLIP",
        "abstract": "Visual reprogramming (VR) reuses pre-trained vision models for downstream image classification tasks by adding trainable noise patterns to inputs. When applied to vision-language models (e.g., CLIP), existing VR approaches follow the same pipeline used in vision models (e.g., ResNet, ViT), where ground-truth class labels are inserted into fixed text templates to guide the optimization of VR patterns. This label-based approach, however, overlooks the rich information and diverse attribute-guided textual representations that CLIP can exploit, which may lead to the misclassification of samples. In this paper, we propose Attribute-based Visual Reprogramming (AttrVR) for CLIP, utilizing descriptive attributes (DesAttrs) and distinctive attributes (DistAttrs), which respectively represent common and unique feature descriptions for different classes. Besides, as images of the same class may reflect different attributes after VR, AttrVR iteratively refines patterns using the $k$-nearest DesAttrs and DistAttrs for each image sample, enabling more dynamic and sample-specific optimization. Theoretically, AttrVR is shown to reduce intra-class variance and increase inter-class separation. Empirically, it achieves superior performance in 12 downstream tasks for both ViT-based and ResNet-based CLIP. The success of AttrVR facilitates more effective integration of VR from unimodal vision models into vision-language models. Our code is available at https://github.com/tmlr-group/AttrVR.",
        "arxiv_id": "2501.13982",
        "ARXIVID": "2501.13982",
        "COMMENT": "Proposes a novel method for visual reprogramming with CLIP, and introduces attribute-guided optimization, aligning with representation learning advancements through strong theoretical innovations.",
        "RELEVANCE": 9,
        "NOVELTY": 8
    },
    "2501.13997": {
        "authors": [
            "Xingsi Dong",
            "Pengxiang Yuan",
            "Si Wu"
        ],
        "title": "Predictive Learning in Energy-based Models with Attractor Structures",
        "abstract": "Predictive models are highly advanced in understanding the mechanisms of brain function. Recent advances in machine learning further underscore the power of prediction for optimal representation in learning. However, there remains a gap in creating a biologically plausible model that explains how the neural system achieves prediction. In this paper, we introduce a framework that employs an energy-based model (EBM) to capture the nuanced processes of predicting observation after action within the neural system, encompassing prediction, learning, and inference. We implement the EBM with a hierarchical structure and integrate a continuous attractor neural network for memory, constructing a biologically plausible model. In experimental evaluations, our model demonstrates efficacy across diverse scenarios. The range of actions includes eye movement, motion in environments, head turning, and static observation while the environment changes. Our model not only makes accurate predictions for environments it was trained on, but also provides reasonable predictions for unseen environments, matching the performances of machine learning methods in multiple tasks. We hope that this study contributes to a deep understanding of how the neural system performs prediction.",
        "arxiv_id": "2501.13997",
        "ARXIVID": "2501.13997",
        "COMMENT": "Proposes a biologically inspired energy-based model (EBM) with hierarchical structures and attractor networks for prediction. The use of EBMs and memory networks represents an innovative approach to representation learning.",
        "RELEVANCE": 8,
        "NOVELTY": 8
    },
    "2501.13986": {
        "authors": [
            "Vivek Bharadwaj",
            "Austin Scott Glover",
            "Aydin Buluc",
            "James Demmel"
        ],
        "title": "An Efficient Sparse Kernel Generator for O(3)-Equivariant Deep Networks",
        "abstract": "Rotation equivariant graph neural networks, i.e., networks designed to guarantee certain geometric relations between their inputs and outputs, yield state-of-the-art performance on spatial deep learning tasks. They exhibit high data efficiency during training and significantly reduced inference time for interatomic potential calculations compared to classical approaches. Key to these models is the Clebsch-Gordon (CG) tensor product, a kernel that contracts two dense feature vectors with a highly structured sparse tensor to produce a dense output vector. The operation, which may be repeated millions of times for typical equivariant models, is a costly and inefficient bottleneck. We introduce a GPU sparse kernel generator for the CG tensor product that provides significant speedup over the best existing open and closed-source implementations. Our implementation achieves high performance by carefully managing GPU shared memory through static analysis at model compile-time, minimizing reads and writes to global memory. We break the tensor product into a series of kernels with operands that fit entirely into registers, enabling us to emit long arithmetic instruction streams that maximize instruction-level parallelism. By fusing the CG tensor product with a subsequent graph convolution, we reduce both intermediate storage and global memory traffic over naive approaches that duplicate input data. We also provide optimized kernels for the gradient of the CG tensor product and a novel identity for the higher partial derivatives required to predict interatomic forces. Our fused kernels offer up to 4.5x speedup for the forward pass and 3x for the backward pass over NVIDIA cuEquivariance, as well as >10x speedup over the widely-used e3nn package. We offer up to 5.3x inference-time speedup for the MACE chemistry foundation model over the original unoptimized version.",
        "arxiv_id": "2501.13986",
        "ARXIVID": "2501.13986",
        "COMMENT": "The paper discusses a computational optimization (sparse kernel generation for O(3)-equivariant deep networks) with a significant focus on sparsity and efficiency, aligning it with the model compression and sparse methods criterion. Novel GPU-based implementations and optimizations further enhance its relevance and novelty.",
        "RELEVANCE": 8,
        "NOVELTY": 7
    },
    "2501.14440": {
        "authors": [
            "Dhiraj Patel",
            "Anton Savostianov",
            "Michael T. Schaub"
        ],
        "title": "Convergence of gradient based training for linear Graph Neural Networks",
        "abstract": "Graph Neural Networks (GNNs) are powerful tools for addressing learning problems on graph structures, with a wide range of applications in molecular biology and social networks. However, the theoretical foundations underlying their empirical performance are not well understood. In this article, we examine the convergence of gradient dynamics in the training of linear GNNs. Specifically, we prove that the gradient flow training of a linear GNN with mean squared loss converges to the global minimum at an exponential rate. The convergence rate depends explicitly on the initial weights and the graph shift operator, which we validate on synthetic datasets from well-known graph models and real-world datasets. Furthermore, we discuss the gradient flow that minimizes the total weights at the global minimum. In addition to the gradient flow, we study the convergence of linear GNNs under gradient descent training, an iterative scheme viewed as a discretization of gradient flow.",
        "arxiv_id": "2501.14440",
        "ARXIVID": "2501.14440",
        "COMMENT": "The paper focuses on the convergence of gradient-based training for linear Graph Neural Networks, which aligns closely with representation learning by investigating training dynamics theoretically. However, it leans more towards GNN-specific theory than general foundational insights.",
        "RELEVANCE": 7,
        "NOVELTY": 7
    },
    "2501.14625": {
        "authors": [
            "David Huang",
            "Francisco Marmolejo-Coss\\'io",
            "Edwin Lock",
            "David Parkes"
        ],
        "title": "Accelerated Preference Elicitation with LLM-Based Proxies",
        "abstract": "Bidders in combinatorial auctions face significant challenges when describing their preferences to an auctioneer. Classical work on preference elicitation focuses on query-based techniques inspired from proper learning--often via proxies that interface between bidders and an auction mechanism--to incrementally learn bidder preferences as needed to compute efficient allocations. Although such elicitation mechanisms enjoy theoretical query efficiency, the amount of communication required may still be too cognitively taxing in practice.   We propose a family of efficient LLM-based proxy designs for eliciting preferences from bidders using natural language. Our proposed mechanism combines LLM pipelines and DNF-proper-learning techniques to quickly approximate preferences when communication is limited. To validate our approach, we create a testing sandbox for elicitation mechanisms that communicate in natural language. In our experiments, our most promising LLM proxy design reaches approximately efficient outcomes with five times fewer queries than classical proper learning based elicitation mechanisms.",
        "arxiv_id": "2501.14625",
        "ARXIVID": "2501.14625",
        "COMMENT": "Combines LLMs with proper learning for preference elicitation in auctions, offering methodological novelty with potential cross-domain relevance in information representation and learning dynamics.",
        "RELEVANCE": 7,
        "NOVELTY": 7
    },
    "2501.14204": {
        "authors": [
            "Xiaoyu Liang",
            "Chaofeng Guan",
            "Jiaying Lu",
            "Huiyao Chen",
            "Huan Wang",
            "Haoji Hu"
        ],
        "title": "Dynamic Token Reduction during Generation for Vision Language Models",
        "abstract": "Vision-Language Models (VLMs) have achieved notable success in multimodal tasks but face practical limitations due to the quadratic complexity of decoder attention mechanisms and autoregressive generation. Existing methods like FASTV and VTW have achieved notable results in reducing redundant visual tokens, but these approaches focus on pruning tokens in a single forward pass without systematically analyzing the redundancy of visual tokens throughout the entire generation process. In this paper, we introduce a dynamic pruning strategy tailored for VLMs, namedDynamic Rate (DyRate), which progressively adjusts the compression rate during generation. Our analysis of the distribution of attention reveals that the importance of visual tokens decreases throughout the generation process, inspiring us to adopt a more aggressive compression rate. By integrating a lightweight predictor based on attention distribution, our approach enables flexible adjustment of pruning rates based on the attention distribution. Our experimental results demonstrate that our method not only reduces computational demands but also maintains the quality of responses.",
        "arxiv_id": "2501.14204",
        "ARXIVID": "2501.14204",
        "COMMENT": "The paper proposes a dynamic token reduction strategy for Vision-Language Models (VLMs), addressing efficiency concerns through pruning strategies. This aligns with compression and efficiency improvements but does not introduce new foundational principles or architectures.",
        "RELEVANCE": 7,
        "NOVELTY": 6
    }
}