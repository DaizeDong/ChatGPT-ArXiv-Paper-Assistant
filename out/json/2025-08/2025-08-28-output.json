{
    "2508.20040": {
        "SCORE": 18,
        "ARXIVID": "2508.20040",
        "COMMENT": "The paper proposes a new discipline called Model Science, which focuses on verification, explanation, and control of AI systems, aligning with the emerging trends criterion by introducing a broad new paradigm.",
        "RELEVANCE": 9,
        "NOVELTY": 9,
        "authors": [
            "Przemyslaw Biecek",
            "Wojciech Samek"
        ],
        "title": "Model Science: getting serious about verification, explanation and control of AI systems",
        "abstract": "The growing adoption of foundation models calls for a paradigm shift from Data Science to Model Science. Unlike data-centric approaches, Model Science places the trained model at the core of analysis, aiming to interact, verify, explain, and control its behavior across diverse operational contexts. This paper introduces a conceptual framework for a new discipline called Model Science, along with the proposal for its four key pillars: Verification, which requires strict, context-aware evaluation protocols; Explanation, which is understood as various approaches to explore of internal model operations; Control, which integrates alignment techniques to steer model behavior; and Interface, which develops interactive and visual explanation tools to improve human calibration and decision-making. The proposed framework aims to guide the development of credible, safe, and human-aligned AI systems.",
        "arxiv_id": "2508.20040"
    },
    "2508.19487": {
        "SCORE": 17,
        "ARXIVID": "2508.19487",
        "COMMENT": "The paper introduces a novel framework EQUATE for symbolic regression using foundation model distillation, aligning with foundational research in representation learning and model compression.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Wangyang Ying",
            "Jinghan Zhang",
            "Haoyue Bai",
            "Nanxu Gong",
            "Xinyuan Wang",
            "Kunpeng Liu",
            "Chandan K. Reddy",
            "Yanjie Fu"
        ],
        "title": "Data-Efficient Symbolic Regression via Foundation Model Distillation",
        "abstract": "Discovering interpretable mathematical equations from observed data (a.k.a. equation discovery or symbolic regression) is a cornerstone of scientific discovery, enabling transparent modeling of physical, biological, and economic systems. While foundation models pre-trained on large-scale equation datasets offer a promising starting point, they often suffer from negative transfer and poor generalization when applied to small, domain-specific datasets. In this paper, we introduce EQUATE (Equation Generation via QUality-Aligned Transfer Embeddings), a data-efficient fine-tuning framework that adapts foundation models for symbolic equation discovery in low-data regimes via distillation. EQUATE combines symbolic-numeric alignment with evaluator-guided embedding optimization, enabling a principled embedding-search-generation paradigm. Our approach reformulates discrete equation search as a continuous optimization task in a shared embedding space, guided by data-equation fitness and simplicity. Experiments across three standard public benchmarks (Feynman, Strogatz, and black-box datasets) demonstrate that EQUATE consistently outperforms state-of-the-art baselines in both accuracy and robustness, while preserving low complexity and fast inference. These results highlight EQUATE as a practical and generalizable solution for data-efficient symbolic regression in foundation model distillation settings.",
        "arxiv_id": "2508.19487"
    },
    "2508.19697": {
        "SCORE": 17,
        "ARXIVID": "2508.19697",
        "COMMENT": "The paper addresses safety alignment in LLMs by distributing safety-related behaviors across attention heads, providing insights into LLM behavior and interpretability.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Chao Huang",
            "Zefeng Zhang",
            "Juewei Yue",
            "Quangang Li",
            "Chuang Zhang",
            "Tingwen Liu"
        ],
        "title": "Safety Alignment Should Be Made More Than Just A Few Attention Heads",
        "abstract": "Current safety alignment for large language models(LLMs) continues to present vulnerabilities, given that adversarial prompting can effectively bypass their safety measures.Our investigation shows that these safety mechanisms predominantly depend on a limited subset of attention heads: removing or ablating these heads can severely compromise model safety. To identify and evaluate these safety-critical components, we introduce RDSHA, a targeted ablation method that leverages the model's refusal direction to pinpoint attention heads mostly responsible for safety behaviors. Further analysis shows that existing jailbreak attacks exploit this concentration by selectively bypassing or manipulating these critical attention heads. To address this issue, we propose AHD, a novel training strategy designed to promote the distributed encoding of safety-related behaviors across numerous attention heads. Experimental results demonstrate that AHD successfully distributes safety-related capabilities across more attention heads. Moreover, evaluations under several mainstream jailbreak attacks show that models trained with AHD exhibit considerably stronger safety robustness, while maintaining overall functional utility.",
        "arxiv_id": "2508.19697"
    },
    "2508.19884": {
        "SCORE": 17,
        "ARXIVID": "2508.19884",
        "COMMENT": "The paper introduces a parameter-free graph neural network framework based on structural diversity, which provides a new theoretical perspective for graph representation learning. This aligns with the representation learning criterion.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Mingyue Kong",
            "Yinglong Zhang",
            "Chengda Xu",
            "Xuewen Xia",
            "Xing Xu"
        ],
        "title": "Parameter-Free Structural-Diversity Message Passing for Graph Neural Networks",
        "abstract": "Graph Neural Networks (GNNs) have shown remarkable performance in structured data modeling tasks such as node classification. However, mainstream approaches generally rely on a large number of trainable parameters and fixed aggregation rules, making it difficult to adapt to graph data with strong structural heterogeneity and complex feature distributions. This often leads to over-smoothing of node representations and semantic degradation. To address these issues, this paper proposes a parameter-free graph neural network framework based on structural diversity, namely SDGNN (Structural-Diversity Graph Neural Network). The framework is inspired by structural diversity theory and designs a unified structural-diversity message passing mechanism that simultaneously captures the heterogeneity of neighborhood structures and the stability of feature semantics, without introducing additional trainable parameters. Unlike traditional parameterized methods, SDGNN does not rely on complex model training, but instead leverages complementary modeling from both structure-driven and feature-driven perspectives, thereby effectively improving adaptability across datasets and scenarios. Experimental results show that on eight public benchmark datasets and an interdisciplinary PubMed citation network, SDGNN consistently outperforms mainstream GNNs under challenging conditions such as low supervision, class imbalance, and cross-domain transfer. This work provides a new theoretical perspective and general approach for the design of parameter-free graph neural networks, and further validates the importance of structural diversity as a core signal in graph representation learning. To facilitate reproducibility and further research, the full implementation of SDGNN has been released at: https://github.com/mingyue15694/SGDNN/tree/main",
        "arxiv_id": "2508.19884"
    },
    "2508.19498": {
        "SCORE": 17,
        "ARXIVID": "2508.19498",
        "COMMENT": "The paper introduces a framework for knowledge transfer from diverse pre-trained models, which aligns with the representation learning criterion by addressing foundational challenges in knowledge integration.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Yimu Wang",
            "Weiming Zhuang",
            "Chen Chen",
            "Jiabo Huang",
            "Jingtao Li",
            "Lingjuan Lyu"
        ],
        "title": "UNIFORM: Unifying Knowledge from Large-scale and Diverse Pre-trained Models",
        "abstract": "In the era of deep learning, the increasing number of pre-trained models available online presents a wealth of knowledge. These models, developed with diverse architectures and trained on varied datasets for different tasks, provide unique interpretations of the real world. Their collective consensus is likely universal and generalizable to unseen data. However, effectively harnessing this collective knowledge poses a fundamental challenge due to the heterogeneity of pre-trained models. Existing knowledge integration solutions typically rely on strong assumptions about training data distributions and network architectures, limiting them to learning only from specific types of models and resulting in data and/or inductive biases. In this work, we introduce a novel framework, namely UNIFORM, for knowledge transfer from a diverse set of off-the-shelf models into one student model without such constraints. Specifically, we propose a dedicated voting mechanism to capture the consensus of knowledge both at the logit level -- incorporating teacher models that are capable of predicting target classes of interest -- and at the feature level, utilizing visual representations learned on arbitrary label spaces. Extensive experiments demonstrate that UNIFORM effectively enhances unsupervised object recognition performance compared to strong knowledge transfer baselines. Notably, it exhibits remarkable scalability by benefiting from over one hundred teachers, while existing methods saturate at a much smaller scale.",
        "arxiv_id": "2508.19498"
    },
    "2508.19445": {
        "SCORE": 17,
        "ARXIVID": "2508.19445",
        "COMMENT": "The paper provides theoretical insights into the surjectivity of neural networks, which is relevant to understanding the behavior and interpretability of large language models.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Haozhe Jiang",
            "Nika Haghtalab"
        ],
        "title": "On Surjectivity of Neural Networks: Can you elicit any behavior from your model?",
        "abstract": "Given a trained neural network, can any specified output be generated by some input? Equivalently, does the network correspond to a function that is surjective? In generative models, surjectivity implies that any output, including harmful or undesirable content, can in principle be generated by the networks, raising concerns about model safety and jailbreak vulnerabilities. In this paper, we prove that many fundamental building blocks of modern neural architectures, such as networks with pre-layer normalization and linear-attention modules, are almost always surjective. As corollaries, widely used generative frameworks, including GPT-style transformers and diffusion models with deterministic ODE solvers, admit inverse mappings for arbitrary outputs. By studying surjectivity of these modern and commonly used neural architectures, we contribute a formalism that sheds light on their unavoidable vulnerability to a broad class of adversarial attacks.",
        "arxiv_id": "2508.19445"
    },
    "2508.19352": {
        "SCORE": 17,
        "ARXIVID": "2508.19352",
        "COMMENT": "The paper provides insights into memorization in GNNs, which is relevant to representation learning and training dynamics in neural networks.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Adarsh Jamadandi",
            "Jing Xu",
            "Adam Dziedzic",
            "Franziska Boenisch"
        ],
        "title": "Memorization in Graph Neural Networks",
        "abstract": "Deep neural networks (DNNs) have been shown to memorize their training data, yet similar analyses for graph neural networks (GNNs) remain largely under-explored. We introduce NCMemo (Node Classification Memorization), the first framework to quantify label memorization in semi-supervised node classification. We first establish an inverse relationship between memorization and graph homophily, i.e., the property that connected nodes share similar labels/features. We find that lower homophily significantly increases memorization, indicating that GNNs rely on memorization to learn less homophilic graphs. Secondly, we analyze GNN training dynamics. We find that the increased memorization in low homophily graphs is tightly coupled to the GNNs' implicit bias on using graph structure during learning. In low homophily regimes, this structure is less informative, hence inducing memorization of the node labels to minimize training loss. Finally, we show that nodes with higher label inconsistency in their feature-space neighborhood are significantly more prone to memorization. Building on our insights into the link between graph homophily and memorization, we investigate graph rewiring as a means to mitigate memorization. Our results demonstrate that this approach effectively reduces memorization without compromising model performance. Moreover, we show that it lowers the privacy risk for previously memorized data points in practice. Thus, our work not only advances understanding of GNN learning but also supports more privacy-preserving GNN deployment.",
        "arxiv_id": "2508.19352"
    },
    "2508.19479": {
        "SCORE": 17,
        "ARXIVID": "2508.19479",
        "COMMENT": "The paper introduces DeepAtlas, an algorithm for manifold learning, which aligns with representation learning by providing insights into how data can be represented in lower-dimensional spaces. It also offers a novel approach to assess the manifold hypothesis.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Serena Hughes",
            "Timothy Hamilton",
            "Tom Kolokotrones",
            "Eric J. Deeds"
        ],
        "title": "DeepAtlas: a tool for effective manifold learning",
        "abstract": "Manifold learning builds on the \"manifold hypothesis,\" which posits that data in high-dimensional datasets are drawn from lower-dimensional manifolds. Current tools generate global embeddings of data, rather than the local maps used to define manifolds mathematically. These tools also cannot assess whether the manifold hypothesis holds true for a dataset. Here, we describe DeepAtlas, an algorithm that generates lower-dimensional representations of the data's local neighborhoods, then trains deep neural networks that map between these local embeddings and the original data. Topological distortion is used to determine whether a dataset is drawn from a manifold and, if so, its dimensionality. Application to test datasets indicates that DeepAtlas can successfully learn manifold structures. Interestingly, many real datasets, including single-cell RNA-sequencing, do not conform to the manifold hypothesis. In cases where data is drawn from a manifold, DeepAtlas builds a model that can be used generatively and promises to allow the application of powerful tools from differential geometry to a variety of datasets.",
        "arxiv_id": "2508.19479"
    },
    "2508.19268": {
        "SCORE": 17,
        "ARXIVID": "2508.19268",
        "COMMENT": "The paper introduces a hybrid Mixture-of-Experts (MoE) model for multilingual code generation, aligning with the Model Architecture criterion.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Qing Wang",
            "Xue Han",
            "Jiahui Wang",
            "Lehao Xing",
            "Qian Hu",
            "Lianlian Zhang",
            "Chao Deng",
            "Junlan Feng"
        ],
        "title": "MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts",
        "abstract": "Despite LLMs' excellent code creation capabilities, multilingual code generation remains extremely challenging. To address this, we intent to improve the multi-programming-lingual (MultiPL) performance of the base LLMs while retaining the most popular ones using restricted computational resources. We consider MultiPL to be a special case of multiple natural languages and propose a MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called MultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize expert selection at both the token and segment levels. The token-level MoE is a standard upcycling MoE structure with a shared expert and a novel gate weight normalization approach that aids in the final fusion with the segment-level MoE. The segment-level MoE incorporates two innovative designs to better capture the syntactic structure and contextual patterns of programming languages: First, using a sliding window to partition the input token sequence into multiple segments; Then, adopting an expert-choice routing strategy that allows experts to select the top-k segments. The results of the experiment proved the effectiveness of MultiPL-MoE.",
        "arxiv_id": "2508.19268"
    },
    "2508.19282": {
        "SCORE": 17,
        "ARXIVID": "2508.19282",
        "COMMENT": "The paper proposes a novel method for lossless compression in retrieval-augmented LLMs, aligning with the Model Compression criterion.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Ziqiang Cui",
            "Yunpeng Weng",
            "Xing Tang",
            "Peiyang Liu",
            "Shiwei Li",
            "Bowei He",
            "Jiamin Chen",
            "Xiuqiang He",
            "Chen Ma"
        ],
        "title": "CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning",
        "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance the timeliness of knowledge and the factual accuracy of responses in Large Language Models (LLMs). However, the inclusion of excessive retrieved documents substantially increases the input length, leading to higher computational costs. Previous studies have attempted to compress retrieved documents into shorter texts before in-context integration, but such methods often compromise end-task performance. The lack of well-defined compression targets forces many approaches to rely on fixed heuristics, which cannot guarantee that the compressed content will effectively support the end task. To address these limitations, we propose CORE, a novel method designed to achieve lossless context compression for RAG. CORE employs reinforcement learning to optimize the compression process without relying on predefined compression labels. Specifically, it utilizes end-task performance as a reward signal and applies Generalized Reinforcement Learning Policy Optimization (GRPO) to train the compressor. This end-to-end training framework enables the compressor to generate summaries that maximize the accuracy of answers generated by the LLM. Extensive experiments on four datasets demonstrate the superiority of our approach. With a high compression ratio of 3\\%, our method not only avoids performance degradation compared to prepending full documents across all datasets but also improves the average Exact Match (EM) score by 3.3 points. The code will be released soon.",
        "arxiv_id": "2508.19282"
    },
    "2508.19842": {
        "SCORE": 16,
        "ARXIVID": "2508.19842",
        "COMMENT": "The paper presents a new symplectic CNN architecture, which is relevant to model architecture innovations, particularly in the context of autoencoders.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "S\\\"uleyman Y{\\i}ld{\\i}z",
            "Konrad Janik",
            "Peter Benner"
        ],
        "title": "Symplectic convolutional neural networks",
        "abstract": "We propose a new symplectic convolutional neural network (CNN) architecture by leveraging symplectic neural networks, proper symplectic decomposition, and tensor techniques. Specifically, we first introduce a mathematically equivalent form of the convolution layer and then, using symplectic neural networks, we demonstrate a way to parameterize the layers of the CNN to ensure that the convolution layer remains symplectic. To construct a complete autoencoder, we introduce a symplectic pooling layer. We demonstrate the performance of the proposed neural network on three examples: the wave equation, the nonlinear Schr\\\"odinger (NLS) equation, and the sine-Gordon equation. The numerical results indicate that the symplectic CNN outperforms the linear symplectic autoencoder obtained via proper symplectic decomposition.",
        "arxiv_id": "2508.19842"
    },
    "2508.19839": {
        "SCORE": 15,
        "ARXIVID": "2508.19839",
        "COMMENT": "The paper introduces a novel data-driven merging method using Particle Swarm Optimization, which is relevant to model architecture and efficiency improvements.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Kehao Zhang",
            "Shaolei Zhang",
            "Yang Feng"
        ],
        "title": "PSO-Merging: Merging Models Based on Particle Swarm Optimization",
        "abstract": "Model merging has emerged as an efficient strategy for constructing multitask models by integrating the strengths of multiple available expert models, thereby reducing the need to fine-tune a pre-trained model for all the tasks from scratch. Existing data-independent methods struggle with performance limitations due to the lack of data-driven guidance. Data-driven approaches also face key challenges: gradient-based methods are computationally expensive, limiting their practicality for merging large expert models, whereas existing gradient-free methods often fail to achieve satisfactory results within a limited number of optimization steps. To address these limitations, this paper introduces PSO-Merging, a novel data-driven merging method based on the Particle Swarm Optimization (PSO). In this approach, we initialize the particle swarm with a pre-trained model, expert models, and sparsified expert models. We then perform multiple iterations, with the final global best particle serving as the merged model. Experimental results on different language models show that PSO-Merging generally outperforms baseline merging methods, offering a more efficient and scalable solution for model merging.",
        "arxiv_id": "2508.19839"
    },
    "2508.19394": {
        "SCORE": 15,
        "ARXIVID": "2508.19394",
        "COMMENT": "The paper presents a hybrid quantum-classical architecture for molecular autoencoding, which is relevant to AI for Science with a focus on foundational research in molecular modeling.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Afrar Jahin",
            "Yi Pan",
            "Yingfeng Wang",
            "Tianming Liu",
            "Wei Zhang"
        ],
        "title": "Quantum-Classical Hybrid Molecular Autoencoder for Advancing Classical Decoding",
        "abstract": "Although recent advances in quantum machine learning (QML) offer significant potential for enhancing generative models, particularly in molecular design, a large array of classical approaches still face challenges in achieving high fidelity and validity. In particular, the integration of QML with sequence-based tasks, such as Simplified Molecular Input Line Entry System (SMILES) string reconstruction, remains underexplored and usually suffers from fidelity degradation. In this work, we propose a hybrid quantum-classical architecture for SMILES reconstruction that integrates quantum encoding with classical sequence modeling to improve quantum fidelity and classical similarity. Our approach achieves a quantum fidelity of approximately 84% and a classical reconstruction similarity of 60%, surpassing existing quantum baselines. Our work lays a promising foundation for future QML applications, striking a balance between expressive quantum representations and classical sequence models and catalyzing broader research on quantum-aware sequence models for molecular and drug discovery.",
        "arxiv_id": "2508.19394"
    },
    "2508.19851": {
        "SCORE": 15,
        "ARXIVID": "2508.19851",
        "COMMENT": "The paper presents a model-agnostic evaluation framework for LLMs using chess, offering insights into LLM behavior and structured reasoning.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Romain Harang",
            "Jason Naradowsky",
            "Yaswitha Gujju",
            "Yusuke Miyao"
        ],
        "title": "Tracking World States with Language Models: State-Based Evaluation Using Chess",
        "abstract": "Large Language Models (LLMs) exhibit emergent capabilities in structured domains, suggesting they may implicitly internalize high-fidelity representations of world models. While probing techniques have shown promising signs of this in scientific and game-based settings, they rely on model-specific internal activations, which limit interpretability and generalizability. In this work, we propose a model-agnostic, state-based evaluation framework using chess as a benchmark to assess whether LLMs preserve the semantics of structured environments. Our method analyzes the downstream legal move distributions (state affordances) to estimate semantic fidelity between predicted and actual game states. This approach offers a more meaningful evaluation than conventional string-based metrics by aligning more closely with the strategic and rule-governed nature of chess. Experimental results demonstrate that our metrics capture deficiencies in state-tracking, highlighting limitations of LLMs in maintaining coherent internal models over long sequences. Our framework provides a robust tool for evaluating structured reasoning in LLMs without requiring internal model access, and generalizes to a wide class of symbolic environments.",
        "arxiv_id": "2508.19851"
    },
    "2508.19982": {
        "SCORE": 15,
        "ARXIVID": "2508.19982",
        "COMMENT": "The paper presents a novel fast decoding paradigm for diffusion language models, which is relevant to model compression and efficiency improvements.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Pengxiang Li",
            "Yefan Zhou",
            "Dilxat Muhtar",
            "Lu Yin",
            "Shilin Yan",
            "Li Shen",
            "Yi Liang",
            "Soroush Vosoughi",
            "Shiwei Liu"
        ],
        "title": "Diffusion Language Models Know the Answer Before Decoding",
        "abstract": "Diffusion language models (DLMs) have recently emerged as an alternative to autoregressive approaches, offering parallel sequence generation and flexible token orders. However, their inference remains slower than that of autoregressive models, primarily due to the cost of bidirectional attention and the large number of refinement steps required for high quality outputs. In this work, we highlight and leverage an overlooked property of DLMs early answer convergence: in many cases, the correct answer can be internally identified by half steps before the final decoding step, both under semi-autoregressive and random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99% of instances, respectively, can be decoded correctly using only half of the refinement steps. Building on this observation, we introduce Prophet, a training-free fast decoding paradigm that enables early commit decoding. Specifically, Prophet dynamically decides whether to continue refinement or to go \"all-in\" (i.e., decode all remaining tokens in one step), using the confidence gap between the top-2 prediction candidates as the criterion. It integrates seamlessly into existing DLM implementations, incurs negligible overhead, and requires no additional training. Empirical evaluations of LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the number of decoding steps by up to 3.4x while preserving high generation quality. These results recast DLM decoding as a problem of when to stop sampling, and demonstrate that early decode convergence provides a simple yet powerful mechanism for accelerating DLM inference, complementary to existing speedup techniques. Our code is publicly available at https://github.com/pixeli99/Prophet.",
        "arxiv_id": "2508.19982"
    },
    "2508.19410": {
        "SCORE": 15,
        "ARXIVID": "2508.19410",
        "COMMENT": "The paper introduces a novel approach to Hamiltonian Neural Networks by using Kolmogorov-Arnold Representation, which aligns with foundational research in model architecture and representation learning.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Zongyu Wu",
            "Ruichen Xu",
            "Luoyao Chen",
            "Georgios Kementzidis",
            "Siyao Wang",
            "Yuefan Deng"
        ],
        "title": "Kolmogorov-Arnold Representation for Symplectic Learning: Advancing Hamiltonian Neural Networks",
        "abstract": "We propose a Kolmogorov-Arnold Representation-based Hamiltonian Neural Network (KAR-HNN) that replaces the Multilayer Perceptrons (MLPs) with univariate transformations. While Hamiltonian Neural Networks (HNNs) ensure energy conservation by learning Hamiltonian functions directly from data, existing implementations, often relying on MLPs, cause hypersensitivity to the hyperparameters while exploring complex energy landscapes. Our approach exploits the localized function approximations to better capture high-frequency and multi-scale dynamics, reducing energy drift and improving long-term predictive stability. The networks preserve the symplectic form of Hamiltonian systems, and thus maintain interpretability and physical consistency. After assessing KAR-HNN on four benchmark problems including spring-mass, simple pendulum, two- and three-body problem, we foresee its effectiveness for accurate and stable modeling of realistic physical processes often at high dimensions and with few known parameters.",
        "arxiv_id": "2508.19410"
    },
    "2508.19563": {
        "SCORE": 15,
        "ARXIVID": "2508.19563",
        "COMMENT": "The paper discusses the robustness issues of LLMs in data fitting, providing theoretical insights into LLM behavior, which aligns with the large language models criterion.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Hejia Liu",
            "Mochen Yang",
            "Gediminas Adomavicius"
        ],
        "title": "Just Because You Can, Doesn't Mean You Should: LLMs for Data Fitting",
        "abstract": "Large Language Models (LLMs) are being applied in a wide array of settings, well beyond the typical language-oriented use cases. In particular, LLMs are increasingly used as a plug-and-play method for fitting data and generating predictions. Prior work has shown that LLMs, via in-context learning or supervised fine-tuning, can perform competitively with many tabular supervised learning techniques in terms of predictive performance. However, we identify a critical vulnerability of using LLMs for data fitting -- making changes to data representation that are completely irrelevant to the underlying learning task can drastically alter LLMs' predictions on the same data. For example, simply changing variable names can sway the size of prediction error by as much as 82% in certain settings. Such prediction sensitivity with respect to task-irrelevant variations manifests under both in-context learning and supervised fine-tuning, for both close-weight and open-weight general-purpose LLMs. Moreover, by examining the attention scores of an open-weight LLM, we discover a non-uniform attention pattern: training examples and variable names/values which happen to occupy certain positions in the prompt receive more attention when output tokens are generated, even though different positions are expected to receive roughly the same attention. This partially explains the sensitivity in the presence of task-irrelevant variations. We also consider a state-of-the-art tabular foundation model (TabPFN) trained specifically for data fitting. Despite being explicitly designed to achieve prediction robustness, TabPFN is still not immune to task-irrelevant variations. Overall, despite LLMs' impressive predictive capabilities, currently they lack even the basic level of robustness to be used as a principled data-fitting tool.",
        "arxiv_id": "2508.19563"
    },
    "2508.19443": {
        "SCORE": 15,
        "ARXIVID": "2508.19443",
        "COMMENT": "The paper discusses tensor decomposition for efficient data generation, aligning with model compression through low-rank approaches.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Paimon Goulart",
            "Shaan Pakala",
            "Evangelos Papalexakis"
        ],
        "title": "Efficiently Generating Multidimensional Calorimeter Data with Tensor Decomposition Parameterization",
        "abstract": "Producing large complex simulation datasets can often be a time and resource consuming task. Especially when these experiments are very expensive, it is becoming more reasonable to generate synthetic data for downstream tasks. Recently, these methods may include using generative machine learning models such as Generative Adversarial Networks or diffusion models. As these generative models improve efficiency in producing useful data, we introduce an internal tensor decomposition to these generative models to even further reduce costs. More specifically, for multidimensional data, or tensors, we generate the smaller tensor factors instead of the full tensor, in order to significantly reduce the model's output and overall parameters. This reduces the costs of generating complex simulation data, and our experiments show the generated data remains useful. As a result, tensor decomposition has the potential to improve efficiency in generative models, especially when generating multidimensional data, or tensors.",
        "arxiv_id": "2508.19443"
    },
    "2508.19614": {
        "SCORE": 15,
        "ARXIVID": "2508.19614",
        "COMMENT": "The paper proposes Layer Fused Decoding (LFD) for retrieval-augmented generation, offering insights into how LLMs integrate external knowledge, which aligns with foundational research in LLM behavior and interpretability.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Yang Sun",
            "Lixin Zou",
            "Dan Luo",
            "Zhiyong Xie",
            "Long Zhang",
            "Liming Dong",
            "Yunwei Zhao",
            "Xixun Lin",
            "Yanxiong Lu",
            "Chenliang Li"
        ],
        "title": "LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation",
        "abstract": "Retrieval-augmented generation (RAG) incorporates external knowledge into large language models (LLMs), improving their adaptability to downstream tasks and enabling information updates. Surprisingly, recent empirical evidence demonstrates that injecting noise into retrieved relevant documents paradoxically facilitates exploitation of external knowledge and improves generation quality. Although counterintuitive and challenging to apply in practice, this phenomenon enables granular control and rigorous analysis of how LLMs integrate external knowledge. Therefore, in this paper, we intervene on noise injection and establish a layer-specific functional demarcation within the LLM: shallow layers specialize in local context modeling, intermediate layers focus on integrating long-range external factual knowledge, and deeper layers primarily rely on parametric internal knowledge. Building on this insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that directly combines representations from an intermediate layer with final-layer decoding outputs to fully exploit the external factual knowledge. To identify the optimal intermediate layer, we introduce an internal knowledge score (IKS) criterion that selects the layer with the lowest IKS value in the latter half of layers. Experimental results across multiple benchmarks demonstrate that LFD helps RAG systems more effectively surface retrieved context knowledge with minimal cost.",
        "arxiv_id": "2508.19614"
    }
}