{
    "2506.20504": {
        "SCORE": 18,
        "ARXIVID": "2506.20504",
        "COMMENT": "The paper discusses the concept of engineering sentience in AI, which is an emerging trend challenging established assumptions about AI capabilities.",
        "RELEVANCE": 9,
        "NOVELTY": 9,
        "authors": [
            "Konstantin Demin",
            "Taylor Webb",
            "Eric Elmoznino",
            "Hakwan Lau"
        ],
        "title": "Engineering Sentience",
        "abstract": "We spell out a definition of sentience that may be useful for designing and building it in machines. We propose that for sentience to be meaningful for AI, it must be fleshed out in functional, computational terms, in enough detail to allow for implementation. Yet, this notion of sentience must also reflect something essentially 'subjective', beyond just having the general capacity to encode perceptual content. For this specific functional notion of sentience to occur, we propose that certain sensory signals need to be both assertoric (persistent) and qualitative. To illustrate the definition in more concrete terms, we sketch out some ways for potential implementation, given current technology. Understanding what it takes for artificial agents to be functionally sentient can also help us avoid creating them inadvertently, or at least, realize that we have created them in a timely manner.",
        "arxiv_id": "2506.20504"
    },
    "2506.20194": {
        "SCORE": 17,
        "ARXIVID": "2506.20194",
        "COMMENT": "The paper introduces a novel framework for dual sparsity in LLMs, focusing on pruning and activation sparsity, which aligns with the model compression criterion.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Ruokai Yin",
            "Yuhang Li",
            "Donghyun Lee",
            "Priyadarshini Panda"
        ],
        "title": "DuoGPT: Training-free Dual Sparsity through Activation-aware Pruning in LLMs",
        "abstract": "Large language models (LLMs) deliver strong performance but are difficult to deploy due to high memory and compute costs. While pruning reduces these demands, most methods ignore activation sparsity observed at runtime. We reinterpret activation sparsity as dynamic structured weight sparsity and propose DuoGPT, a unified framework that constructs dual-sparse (spMspV) workloads by combining unstructured weight pruning with activation sparsity. To preserve accuracy, we extend the Optimal Brain Compression (OBC) framework with activation-aware calibration and introduce output residuals from the dense model as correction terms. We further optimize the solution for efficient GPU execution, enabling scalability to billion-parameter LLMs. Evaluations on LLaMA-2 and LLaMA-3 show that DuoGPT outperforms state-of-the-art structured pruning methods by up to 9.17% accuracy at an iso-speedup of 1.39$\\times$ compared to the baseline dense model.",
        "arxiv_id": "2506.20194"
    },
    "2506.20354": {
        "SCORE": 17,
        "ARXIVID": "2506.20354",
        "COMMENT": "The paper introduces a novel self-attention mechanism and a generative foundation model, relevant to model architecture and foundational model research.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Francesco Carzaniga",
            "Michael Hersche",
            "Abu Sebastian",
            "Kaspar Schindler",
            "Abbas Rahimi"
        ],
        "title": "A foundation model with multi-variate parallel attention to generate neuronal activity",
        "abstract": "Learning from multi-variate time-series with heterogeneous channel configurations remains a fundamental challenge for deep neural networks (DNNs), particularly in clinical domains such as intracranial electroencephalography (iEEG), where channel setups vary widely across subjects. In this work, we introduce multi-variate parallel attention (MVPA), a novel self-attention mechanism that disentangles content, temporal, and spatial attention, enabling flexible, generalizable, and efficient modeling of time-series data with varying channel counts and configurations. We use MVPA to build MVPFormer, a generative foundation model for human electrophysiology, trained to predict the evolution of iEEG signals across diverse subjects. To support this and future effort by the community, we release the SWEC iEEG dataset, the largest publicly available iEEG dataset to date, comprising nearly 10,000 hours of recordings from heterogeneous clinical sources. MVPFormer leverages MVPA to achieve strong generalization across subjects, demonstrating expert-level performance in seizure detection and outperforming state-of-the-art Transformer baselines on our SWEC, the MAYO, and the FNUSA dataset. We further validate MVPA on standard time-series forecasting and classification tasks, where it matches or exceeds existing attention-based models. Together, our contributions establish MVPA as a general-purpose attention mechanism for heterogeneous time-series and MVPFormer as the first open-source, open-weights, and open-data iEEG foundation model with state-of-the-art clinical performance. The code is available at https://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG dataset is available at https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg.",
        "arxiv_id": "2506.20354"
    },
    "2506.20533": {
        "SCORE": 17,
        "ARXIVID": "2506.20533",
        "COMMENT": "The paper provides theoretical insights into Iteratively Reweighted Least Squares (IRLS) for robust subspace recovery, which is relevant to representation learning.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Gilad Lerman",
            "Kang Li",
            "Tyler Maunu",
            "Teng Zhang"
        ],
        "title": "Global Convergence of Iteratively Reweighted Least Squares for Robust Subspace Recovery",
        "abstract": "Robust subspace estimation is fundamental to many machine learning and data analysis tasks. Iteratively Reweighted Least Squares (IRLS) is an elegant and empirically effective approach to this problem, yet its theoretical properties remain poorly understood. This paper establishes that, under deterministic conditions, a variant of IRLS with dynamic smoothing regularization converges linearly to the underlying subspace from any initialization. We extend these guarantees to affine subspace estimation, a setting that lacks prior recovery theory. Additionally, we illustrate the practical benefits of IRLS through an application to low-dimensional neural network training. Our results provide the first global convergence guarantees for IRLS in robust subspace recovery and, more broadly, for nonconvex IRLS on a Riemannian manifold.",
        "arxiv_id": "2506.20533"
    },
    "2506.20249": {
        "SCORE": 17,
        "ARXIVID": "2506.20249",
        "COMMENT": "The paper discusses a novel approach to discovering language model architectures using a multi-agent LLM system, which aligns with foundational research in LLMs.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Junyan Cheng",
            "Peter Clark",
            "Kyle Richardson"
        ],
        "title": "Language Modeling by Language Models",
        "abstract": "Can we leverage LLMs to model the process of discovering novel language model (LM) architectures? Inspired by real research, we propose a multi-agent LLM approach that simulates the conventional stages of research, from ideation and literature search (proposal stage) to design implementation (code generation), generative pre-training, and downstream evaluation (verification). Using ideas from scaling laws, our system, Genesys, employs a Ladder of Scales approach; new designs are proposed, adversarially reviewed, implemented, and selectively verified at increasingly larger model scales (14M$\\sim$350M parameters) with a narrowing budget (the number of models we can train at each scale). To help make discovery efficient and factorizable, Genesys uses a novel genetic programming backbone, which we show has empirical advantages over commonly used direct prompt generation workflows (e.g., $\\sim$86\\% percentage point improvement in successful design generation, a key bottleneck). We report experiments involving 1,162 newly discovered designs (1,062 fully verified through pre-training) and find the best designs to be highly competitive with known architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common benchmarks). We couple these results with comprehensive system-level ablations and formal results, which give broader insights into the design of effective autonomous discovery systems.",
        "arxiv_id": "2506.20249"
    },
    "2506.19960": {
        "SCORE": 17,
        "ARXIVID": "2506.19960",
        "COMMENT": "The paper presents a novel transferable wavefunction model, Orbformer, which is a foundational research in molecular modeling, aligning with AI for Science.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Adam Foster",
            "Zeno Sch\\\"atzle",
            "P. Bern\\'at Szab\\'o",
            "Lixue Cheng",
            "Jonas K\\\"ohler",
            "Gino Cassella",
            "Nicholas Gao",
            "Jiawei Li",
            "Frank No\\'e",
            "Jan Hermann"
        ],
        "title": "An ab initio foundation model of wavefunctions that accurately describes chemical bond breaking",
        "abstract": "Reliable description of bond breaking remains a major challenge for quantum chemistry due to the multireferential character of the electronic structure in dissociating species. Multireferential methods in particular suffer from large computational cost, which under the normal paradigm has to be paid anew for each system at a full price, ignoring commonalities in electronic structure across molecules. Quantum Monte Carlo with deep neural networks (deep QMC) uniquely offers to exploit such commonalities by pretraining transferable wavefunction models, but all such attempts were so far limited in scope. Here, we bring this new paradigm to fruition with Orbformer, a novel transferable wavefunction model pretrained on 22,000 equilibrium and dissociating structures that can be fine-tuned on unseen molecules reaching an accuracy-cost ratio rivalling classical multireferential methods. On established benchmarks as well as more challenging bond dissociations and Diels-Alder reactions, Orbformer is the only method that consistently converges to chemical accuracy (1 kcal/mol). This work turns the idea of amortizing the cost of solving the Schr\\\"odinger equation over many molecules into a practical approach in quantum chemistry.",
        "arxiv_id": "2506.19960"
    },
    "2506.20040": {
        "SCORE": 17,
        "ARXIVID": "2506.20040",
        "COMMENT": "The paper introduces a framework for interpreting language models using vector quantization, relevant to representation learning and model architecture analysis.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Ankur Garg",
            "Xuemin Yu",
            "Hassan Sajjad",
            "Samira Ebrahimi Kahou"
        ],
        "title": "Cross-Layer Discrete Concept Discovery for Interpreting Language Models",
        "abstract": "Uncovering emergent concepts across transformer layers remains a significant challenge because the residual stream linearly mixes and duplicates information, obscuring how features evolve within large language models. Current research efforts primarily inspect neural representations at single layers, thereby overlooking this cross-layer superposition and the redundancy it introduces. These representations are typically either analyzed directly for activation patterns or passed to probing classifiers that map them to a limited set of predefined concepts. To address these limitations, we propose \\gls{clvqvae}, a framework that uses vector quantization to map representations across layers and in the process collapse duplicated residual-stream features into compact, interpretable concept vectors. Our approach uniquely combines top-$k$ temperature-based sampling during quantization with EMA codebook updates, providing controlled exploration of the discrete latent space while maintaining code-book diversity. We further enhance the framework with scaled-spherical k-means++ for codebook initialization, which clusters by directional similarity rather than magnitude, better aligning with semantic structure in word embedding space.",
        "arxiv_id": "2506.20040"
    },
    "2506.20353": {
        "SCORE": 16,
        "ARXIVID": "2506.20353",
        "COMMENT": "The paper proposes a dual-level importance protection mechanism for SVD-based compression, which is relevant to model compression through low-rank approaches.",
        "RELEVANCE": 9,
        "NOVELTY": 7,
        "authors": [
            "Xuan Ding",
            "Rui Sun",
            "Yunjian Zhang",
            "Xiu Yan",
            "Yueqi Zhou",
            "Kaihao Huang",
            "Suzhong Fu",
            "Chuanlong Xie",
            "Yao Zhu"
        ],
        "title": "DipSVD: Dual-importance Protected SVD for Efficient LLM Compression",
        "abstract": "The ever-increasing computational demands and deployment costs of large language models (LLMs) have spurred numerous compressing methods. Compared to quantization and unstructured pruning, SVD compression offers superior hardware compatibility and theoretical guarantees. However, existing SVD-based methods focus on the overall discrepancy between the original and compressed matrices while overlooking the protection of critical components within the matrix, which leads to inferior performance in the compressed models. This paper proposes a dual-level importance protection mechanism to enhance SVD-based compression methods: (1) local importance protection: preserving the most critical singular vectors within each weight matrix through channel-weighted data whitening; and (2) global importance protection: enabling less important layers to bear a greater portion of the compression burden through either a heuristic or optimization-based approach, thereby minimizing the impact of compression on critical layers. Extensive experiments demonstrate that DipSVD outperforms existing SVD-based compression approaches across multiple benchmarks, achieving superior model performance especially at high model compression ratios.",
        "arxiv_id": "2506.20353"
    },
    "2506.19891": {
        "SCORE": 16,
        "ARXIVID": "2506.19891",
        "COMMENT": "The paper presents a novel class-aware soft pruning framework, which aligns with the model compression criterion, focusing on pruning techniques.",
        "RELEVANCE": 9,
        "NOVELTY": 7,
        "authors": [
            "Qinghui Gong",
            "Xue Yang",
            "Xiaohu Tang"
        ],
        "title": "Orthogonal Soft Pruning for Efficient Class Unlearning",
        "abstract": "Machine unlearning aims to selectively remove class-specific knowledge from pretrained neural networks to satisfy privacy regulations such as the GDPR. Existing methods typically face a trade-off between unlearning speed and preservation of predictive accuracy, often incurring either high computational overhead or significant performance degradation on retained classes. In this paper, we propose a novel class-aware soft pruning framework leveraging orthogonal convolutional kernel regularization to achieve rapid and precise forgetting with millisecond-level response times. By enforcing orthogonality constraints during training, our method decorrelates convolutional filters and disentangles feature representations, while efficiently identifying class-specific channels through activation difference analysis. Extensive evaluations across multiple architectures and datasets demonstrate stable pruning with near-instant execution, complete forgetting of targeted classes, and minimal accuracy loss on retained data. Experiments on CIFAR-10, CIFAR-100, and TinyImageNet confirm that our approach substantially reduces membership inference attack risks and accelerates unlearning by orders of magnitude compared to state-of-the-art baselines. This framework provides an efficient, practical solution for real-time machine unlearning in Machine Learning as a Service (MLaaS) scenarios.",
        "arxiv_id": "2506.19891"
    },
    "2506.20649": {
        "SCORE": 16,
        "ARXIVID": "2506.20649",
        "COMMENT": "The paper proposes a disentangled representation learning methodology, which is relevant to representation learning.",
        "RELEVANCE": 9,
        "NOVELTY": 7,
        "authors": [
            "Jacopo Dapueto",
            "Vito Paolo Pastore",
            "Nicoletta Noceti",
            "Francesca Odone"
        ],
        "title": "Disentangled representations of microscopy images",
        "abstract": "Microscopy image analysis is fundamental for different applications, from diagnosis to synthetic engineering and environmental monitoring. Modern acquisition systems have granted the possibility to acquire an escalating amount of images, requiring a consequent development of a large collection of deep learning-based automatic image analysis methods. Although deep neural networks have demonstrated great performance in this field, interpretability, an essential requirement for microscopy image analysis, remains an open challenge.   This work proposes a Disentangled Representation Learning (DRL) methodology to enhance model interpretability for microscopy image classification. Exploiting benchmark datasets from three different microscopic image domains (plankton, yeast vacuoles, and human cells), we show how a DRL framework, based on transferring a representation learnt from synthetic data, can provide a good trade-off between accuracy and interpretability in this domain.",
        "arxiv_id": "2506.20649"
    },
    "2506.20666": {
        "SCORE": 16,
        "ARXIVID": "2506.20666",
        "COMMENT": "The paper uses cognitive models to interpret value trade-offs in LLMs, providing insights into LLM behavior and interpretability.",
        "RELEVANCE": 9,
        "NOVELTY": 7,
        "authors": [
            "Sonia K. Murthy",
            "Rosie Zhao",
            "Jennifer Hu",
            "Sham Kakade",
            "Markus Wulfmeier",
            "Peng Qian",
            "Tomer Ullman"
        ],
        "title": "Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs",
        "abstract": "Navigating everyday social situations often requires juggling conflicting goals, such as conveying a harsh truth, maintaining trust, all while still being mindful of another person's feelings. These value trade-offs are an integral part of human decision-making and language use, however, current tools for interpreting such dynamic and multi-faceted notions of values in LLMs are limited. In cognitive science, so-called \"cognitive models\" provide formal accounts of these trade-offs in humans, by modeling the weighting of a speaker's competing utility functions in choosing an action or utterance. In this work, we use a leading cognitive model of polite speech to interpret the extent to which LLMs represent human-like trade-offs. We apply this lens to systematically evaluate value trade-offs in two encompassing model settings: degrees of reasoning \"effort\" in frontier black-box models, and RL post-training dynamics of open-source models. Our results highlight patterns of higher informational utility than social utility in reasoning models, and in open-source models shown to be stronger in mathematical reasoning. Our findings from LLMs' training dynamics suggest large shifts in utility values early on in training with persistent effects of the choice of base model and pretraining data, compared to feedback dataset or alignment method. We show that our method is responsive to diverse aspects of the rapidly evolving LLM landscape, with insights for forming hypotheses about other high-level behaviors, shaping training regimes for reasoning models, and better controlling trade-offs between values during model training.",
        "arxiv_id": "2506.20666"
    },
    "2506.20241": {
        "SCORE": 16,
        "ARXIVID": "2506.20241",
        "COMMENT": "The paper proposes structured reasoning to enhance LLMs, which is relevant to foundational research in LLM architecture and theoretical insights.",
        "RELEVANCE": 9,
        "NOVELTY": 7,
        "authors": [
            "Yubo Dong",
            "Hehe Fan"
        ],
        "title": "Enhancing Large Language Models through Structured Reasoning",
        "abstract": "Recent Large Language Models (LLMs) have significantly advanced natural language processing and automated decision-making. However, these models still encounter difficulties when performing complex reasoning tasks involving logical deduction and systematic planning, primarily due to their reliance on implicit statistical relationships without structured knowledge representation.Inspired by cognitive science and neurosymbolic AI, we introduce a novel approach to enhance LLMs through explicit structured reasoning. First, we convert unstructured data into structured formats by explicitly annotating reasoning steps. We then employ this structured dataset to train LLMs through Supervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning capabilities of LLMs using Group Relative Policy Optimization (GRPO), incorporating two innovative algorithms--MAX-Flow and Longest Common Subsequence (LCS)--which notably improve reasoning effectiveness and reduce computational complexity. Experimental results from fine-tuning a DeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust performance across various scenarios, and improved compatibility with optimization techniques, validating the efficacy of structured reasoning integration in LLMs.",
        "arxiv_id": "2506.20241"
    },
    "2506.19923": {
        "SCORE": 16,
        "ARXIVID": "2506.19923",
        "COMMENT": "The paper presents a novel AI agent for automated theorem proving, integrating LLMs with a formal proof assistant, relevant to LLM theoretical insights.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Kaito Baba",
            "Chaoran Liu",
            "Shuhei Kurita",
            "Akiyoshi Sannai"
        ],
        "title": "Prover Agent: An Agent-based Framework for Formal Mathematical Proofs",
        "abstract": "We present Prover Agent, a novel AI agent for automated theorem proving that integrates large language models (LLMs) with a formal proof assistant, Lean. Prover Agent coordinates an informal reasoning LLM, a formal prover model, and feedback from Lean while also generating auxiliary lemmas to assist in discovering the overall proof strategy. It achieves an 86.1% success rate on the MiniF2F benchmark, establishing a new state-of-the-art among methods using small language models (SLMs) with a much lower sample budget than previous approaches. We also present case studies illustrating how these generated lemmas contribute to solving challenging problems.",
        "arxiv_id": "2506.19923"
    },
    "2506.20486": {
        "SCORE": 16,
        "ARXIVID": "2506.20486",
        "COMMENT": "The paper introduces Mixtures of Neural Cellular Automata, a novel framework for modeling stochastic dynamical systems, which is relevant to emerging trends in model architecture.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Salvatore Milite",
            "Giulio Caravagna",
            "Andrea Sottoriva"
        ],
        "title": "Mixtures of Neural Cellular Automata: A Stochastic Framework for Growth Modelling and Self-Organization",
        "abstract": "Neural Cellular Automata (NCAs) are a promising new approach to model self-organizing processes, with potential applications in life science. However, their deterministic nature limits their ability to capture the stochasticity of real-world biological and physical systems.   We propose the Mixture of Neural Cellular Automata (MNCA), a novel framework incorporating the idea of mixture models into the NCA paradigm. By combining probabilistic rule assignments with intrinsic noise, MNCAs can model diverse local behaviors and reproduce the stochastic dynamics observed in biological processes.   We evaluate the effectiveness of MNCAs in three key domains: (1) synthetic simulations of tissue growth and differentiation, (2) image morphogenesis robustness, and (3) microscopy image segmentation. Results show that MNCAs achieve superior robustness to perturbations, better recapitulate real biological growth patterns, and provide interpretable rule segmentation. These findings position MNCAs as a promising tool for modeling stochastic dynamical systems and studying self-growth processes.",
        "arxiv_id": "2506.20486"
    },
    "2506.19862": {
        "SCORE": 15,
        "ARXIVID": "2506.19862",
        "COMMENT": "The paper introduces a novel network architecture for biomolecular modeling, which aligns with the AI for Science criterion, focusing on foundational research in molecular modeling.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Junjie Xu",
            "Jiahao Zhang",
            "Mangal Prakash",
            "Xiang Zhang",
            "Suhang Wang"
        ],
        "title": "DualEquiNet: A Dual-Space Hierarchical Equivariant Network for Large Biomolecules",
        "abstract": "Geometric graph neural networks (GNNs) that respect E(3) symmetries have achieved strong performance on small molecule modeling, but they face scalability and expressiveness challenges when applied to large biomolecules such as RNA and proteins. These systems require models that can simultaneously capture fine-grained atomic interactions, long-range dependencies across spatially distant components, and biologically relevant hierarchical structure, such as atoms forming residues, which in turn form higher-order domains. Existing geometric GNNs, which typically operate exclusively in either Euclidean or Spherical Harmonics space, are limited in their ability to capture both the fine-scale atomic details and the long-range, symmetry-aware dependencies required for modeling the multi-scale structure of large biomolecules. We introduce DualEquiNet, a Dual-Space Hierarchical Equivariant Network that constructs complementary representations in both Euclidean and Spherical Harmonics spaces to capture local geometry and global symmetry-aware features. DualEquiNet employs bidirectional cross-space message passing and a novel Cross-Space Interaction Pooling mechanism to hierarchically aggregate atomic features into biologically meaningful units, such as residues, enabling efficient and expressive multi-scale modeling for large biomolecular systems. DualEquiNet achieves state-of-the-art performance on multiple existing benchmarks for RNA property prediction and protein modeling, and outperforms prior methods on two newly introduced 3D structural benchmarks demonstrating its broad effectiveness across a range of large biomolecule modeling tasks.",
        "arxiv_id": "2506.19862"
    },
    "2506.20167": {
        "SCORE": 15,
        "ARXIVID": "2506.20167",
        "COMMENT": "The paper introduces a structural encoder for embedding-driven decoding, which aligns with representation learning and model architecture insights.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Fengze Li",
            "Yue Wang",
            "Yangle Liu",
            "Ming Huang",
            "Dou Hong",
            "Jieming Ma"
        ],
        "title": "SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs",
        "abstract": "Multivariate time series forecasting requires models to simultaneously capture variable-wise structural dependencies and generalize across diverse tasks. While structural encoders are effective in modeling feature interactions, they lack the capacity to support semantic-level reasoning or task adaptation. Conversely, large language models (LLMs) possess strong generalization capabilities but remain incompatible with raw time series inputs. This gap limits the development of unified, transferable prediction systems. Therefore, we introduce SEED, a structural encoder for embedding-driven decoding, which integrates four stages: a token-aware encoder for patch extraction, a projection module that aligns patches with language model embeddings, a semantic reprogramming mechanism that maps patches to task-aware prototypes, and a frozen language model for prediction. This modular architecture decouples representation learning from inference, enabling efficient alignment between numerical patterns and semantic reasoning. Empirical results demonstrate that the proposed method achieves consistent improvements over strong baselines, and comparative studies on various datasets confirm SEED's role in addressing the structural-semantic modeling gap.",
        "arxiv_id": "2506.20167"
    },
    "2506.20178": {
        "SCORE": 15,
        "ARXIVID": "2506.20178",
        "COMMENT": "The paper proposes an uncertainty-guarding selection framework for foundation models, relevant to foundational model research.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Zhiyuan Wang",
            "Jinhao Duan",
            "Qingni Wang",
            "Xiaofeng Zhu",
            "Tianlong Chen",
            "Xiaoshuang Shi",
            "Kaidi Xu"
        ],
        "title": "COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees",
        "abstract": "Uncertainty quantification (UQ) for foundation models is essential to identify and mitigate potential hallucinations in automatically generated text. However, heuristic UQ approaches lack formal guarantees for key metrics such as the false discovery rate (FDR) in selective prediction. Previous work adopts the split conformal prediction (SCP) framework to ensure desired coverage of admissible answers by constructing prediction sets, but these sets often contain incorrect candidates, limiting their practical utility. To address this, we propose COIN, an uncertainty-guarding selection framework that calibrates statistically valid thresholds to filter a single generated answer per question under user-specified FDR constraints. COIN estimates the empirical error rate on a calibration set and applies confidence interval methods such as Clopper-Pearson to establish a high-probability upper bound on the true error rate (i.e., FDR). This enables the selection of the largest uncertainty threshold that ensures FDR control on test data while significantly increasing sample retention. We demonstrate COIN's robustness in risk control, strong test-time power in retaining admissible answers, and predictive efficiency under limited calibration data across both general and multimodal text generation tasks. Furthermore, we show that employing alternative upper bound constructions and UQ strategies can further boost COIN's power performance, which underscores its extensibility and adaptability to diverse application scenarios.",
        "arxiv_id": "2506.20178"
    },
    "2506.20650": {
        "SCORE": 15,
        "ARXIVID": "2506.20650",
        "COMMENT": "The paper introduces novel surrogate loss functions and algorithms for learning to defer with multiple experts, which is relevant to model architecture and efficiency.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Anqi Mao",
            "Mehryar Mohri",
            "Yutao Zhong"
        ],
        "title": "Mastering Multiple-Expert Routing: Realizable $H$-Consistency and Strong Guarantees for Learning to Defer",
        "abstract": "The problem of learning to defer with multiple experts consists of optimally assigning input instances to experts, balancing the trade-off between their accuracy and computational cost. This is a critical challenge in natural language generation, but also in other fields such as image processing, and medical diagnostics. Recent studies have proposed surrogate loss functions to optimize deferral, but challenges remain in ensuring their consistency properties. This paper introduces novel surrogate loss functions and efficient algorithms with strong theoretical learning guarantees. We address open questions regarding realizable $H$-consistency, $H$-consistency bounds, and Bayes-consistency for both single-stage (jointly learning predictor and deferral function) and two-stage (learning only the deferral function with a fixed expert) learning scenarios. For single-stage deferral, we introduce a family of new realizable $H$-consistent surrogate losses and further prove $H$-consistency for a selected member. For two-stage deferral, we derive new surrogate losses that achieve realizable $H$-consistency, $H$-consistency bounds, and Bayes-consistency for the two-expert scenario and, under natural assumptions, multiple-expert scenario. Additionally, we provide enhanced theoretical guarantees under low-noise assumptions for both scenarios. Finally, we report the results of experiments using our proposed surrogate losses, comparing their performance against existing baselines.",
        "arxiv_id": "2506.20650"
    },
    "2506.20362": {
        "SCORE": 15,
        "ARXIVID": "2506.20362",
        "COMMENT": "The paper presents a novel self-supervised graph learning framework using spectral bootstrapping, which is relevant to representation learning.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Lorenzo Bini",
            "Stephane Marchand-Maillet"
        ],
        "title": "Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations",
        "abstract": "We present LaplaceGNN, a novel self-supervised graph learning framework that bypasses the need for negative sampling by leveraging spectral bootstrapping techniques. Our method integrates Laplacian-based signals into the learning process, allowing the model to effectively capture rich structural representations without relying on contrastive objectives or handcrafted augmentations. By focusing on positive alignment, LaplaceGNN achieves linear scaling while offering a simpler, more efficient, self-supervised alternative for graph neural networks, applicable across diverse domains. Our contributions are twofold: we precompute spectral augmentations through max-min centrality-guided optimization, enabling rich structural supervision without relying on handcrafted augmentations, then we integrate an adversarial bootstrapped training scheme that further strengthens feature learning and robustness. Our extensive experiments on different benchmark datasets show that LaplaceGNN achieves superior performance compared to state-of-the-art self-supervised graph methods, offering a promising direction for efficiently learning expressive graph representations.",
        "arxiv_id": "2506.20362"
    },
    "2506.19935": {
        "SCORE": 15,
        "ARXIVID": "2506.19935",
        "COMMENT": "The paper explores masked diffusion models within a decoder-only framework, offering insights into architectural influences and paradigm differences, which aligns with the model architecture criterion.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Shuchen Xue",
            "Tianyu Xie",
            "Tianyang Hu",
            "Zijin Feng",
            "Jiacheng Sun",
            "Kenji Kawaguchi",
            "Zhenguo Li",
            "Zhi-Ming Ma"
        ],
        "title": "Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture",
        "abstract": "Large language models (LLMs) predominantly use autoregressive (AR) approaches, but masked diffusion models (MDMs) are emerging as viable alternatives. A key challenge in comparing AR and MDM paradigms is their typical architectural difference: AR models are often decoder-only, while MDMs have largely been encoder-only. This practice of changing both the modeling paradigm and architecture simultaneously makes direct comparisons unfair, as it's hard to distinguish whether observed differences stem from the paradigm itself or the architectural shift. This research evaluates MDMs within a decoder-only framework to: (1) equitably compare MDM (as Any-Order AR, or AO-AR) and standard AR paradigms. Our investigation suggests that the standard AO-AR objective, which averages over all token permutations, may benefit from refinement, as many permutations appear less informative compared to the language's inherent left-to-right structure. (2) Investigate architectural influences (decoder-only vs. encoder-only) within MDMs. We demonstrate that while encoder-only MDMs model a simpler conditional probability space, decoder-only MDMs can achieve dramatic generation speedups ($\\sim25\\times$) and comparable perplexity with temperature annealing despite modeling a vastly larger space, highlighting key trade-offs. This work thus decouples core paradigm differences from architectural influences, offering insights for future model design. Code is available at https://github.com/scxue/AO-GPT-MDM.",
        "arxiv_id": "2506.19935"
    },
    "2506.20344": {
        "SCORE": 15,
        "ARXIVID": "2506.20344",
        "COMMENT": "The paper provides a comprehensive study of the loss landscape of regularized deep matrix factorization, contributing to the understanding of training dynamics in neural networks.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Po Chen",
            "Rujun Jiang",
            "Peng Wang"
        ],
        "title": "A Complete Loss Landscape Analysis of Regularized Deep Matrix Factorization",
        "abstract": "Despite its wide range of applications across various domains, the optimization foundations of deep matrix factorization (DMF) remain largely open. In this work, we aim to fill this gap by conducting a comprehensive study of the loss landscape of the regularized DMF problem. Toward this goal, we first provide a closed-form expression of all critical points. Building on this, we establish precise conditions under which a critical point is a local minimizer, a global minimizer, a strict saddle point, or a non-strict saddle point. Leveraging these results, we derive a necessary and sufficient condition under which each critical point is either a local minimizer or a strict saddle point. This provides insights into why gradient-based methods almost always converge to a local minimizer of the regularized DMF problem. Finally, we conduct numerical experiments to visualize its loss landscape under different settings to support our theory.",
        "arxiv_id": "2506.20344"
    },
    "2506.20251": {
        "SCORE": 15,
        "ARXIVID": "2506.20251",
        "COMMENT": "The paper addresses safety risks and quantization-aware safety patching for quantized LLMs, which aligns with model compression and efficiency breakthroughs.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Kejia Chen",
            "Jiawen Zhang",
            "Jiacong Hu",
            "Yu Wang",
            "Jian Lou",
            "Zunlei Feng",
            "Mingli Song"
        ],
        "title": "Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models",
        "abstract": "Quantized large language models (LLMs) have gained increasing attention and significance for enabling deployment in resource-constrained environments. However, emerging studies on a few calibration dataset-free quantization methods suggest that quantization may compromise the safety capabilities of LLMs, underscoring the urgent need for systematic safety evaluations and effective mitigation strategies. In this paper, we present comprehensive safety evaluations across various mainstream quantization techniques and diverse calibration datasets, utilizing widely accepted safety benchmarks. To address the identified safety vulnerabilities, we propose a quantization-aware safety patching framework, Q-resafe, to efficiently restore the safety capabilities of quantized LLMs while minimizing any adverse impact on utility. Extensive experimental results demonstrate that Q-resafe successfully re-aligns the safety of quantized LLMs with their pre-quantization counterparts, even under challenging evaluation scenarios. Project page is available at: https://github.com/Thecommonirin/Qresafe.",
        "arxiv_id": "2506.20251"
    },
    "2506.20623": {
        "SCORE": 15,
        "ARXIVID": "2506.20623",
        "COMMENT": "The paper explores closed-loop learning dynamics in exponential families, which aligns with representation learning by examining how models encode information and the training dynamics.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Fariba Jangjoo",
            "Matteo Marsili",
            "Yasser Roudi"
        ],
        "title": "Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning",
        "abstract": "Closed-loop learning is the process of repeatedly estimating a model from data generated from the model itself. It is receiving great attention due to the possibility that large neural network models may, in the future, be primarily trained with data generated by artificial neural networks themselves. We study this process for models that belong to exponential families, deriving equations of motions that govern the dynamics of the parameters. We show that maximum likelihood estimation of the parameters endows sufficient statistics with the martingale property and that as a result the process converges to absorbing states that amplify initial biases present in the data. However, we show that this outcome may be prevented by polluting the data with an infinitesimal fraction of data points generated from a fixed model, by relying on maximum a posteriori estimation or by introducing regularisation. Furthermore, we show that the asymptotic behavior of the dynamics is not reparametrisation invariant.",
        "arxiv_id": "2506.20623"
    },
    "2506.20260": {
        "SCORE": 15,
        "ARXIVID": "2506.20260",
        "COMMENT": "The paper addresses model multiplicity and proposes an argumentative ensembling method, which is relevant to model architecture and theoretical insights into model behavior.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Junqi Jiang",
            "Antonio Rago",
            "Francesco Leofante",
            "Francesca Toni"
        ],
        "title": "Argumentative Ensembling for Robust Recourse under Model Multiplicity",
        "abstract": "In machine learning, it is common to obtain multiple equally performing models for the same prediction task, e.g., when training neural networks with different random seeds. Model multiplicity (MM) is the situation which arises when these competing models differ in their predictions for the same input, for which ensembling is often employed to determine an aggregation of the outputs. Providing recourse recommendations via counterfactual explanations (CEs) under MM thus becomes complex, since the CE may not be valid across all models, i.e., the CEs are not robust under MM. In this work, we formalise the problem of providing recourse under MM, which we name recourse-aware ensembling (RAE). We propose the idea that under MM, CEs for each individual model should be considered alongside their predictions so that the aggregated prediction and recourse are decided in tandem. Centred around this intuition, we introduce six desirable properties for solutions to this problem. For solving RAE, we propose a novel argumentative ensembling method which guarantees the robustness of CEs under MM. Specifically, our method leverages computational argumentation to explicitly represent the conflicts between models and counterfactuals regarding prediction results and CE validity. It then uses argumentation semantics to resolve the conflicts and obtain the final solution, in a manner which is parametric to the chosen semantics. Our method also allows for the specification of preferences over the models under MM, allowing further customisation of the ensemble. In a comprehensive theoretical analysis, we characterise the behaviour of argumentative ensembling with four different argumentation semantics. We then empirically demonstrate the effectiveness of our approach in satisfying desirable properties with eight instantiations of our method. (Abstract is shortened for arXiv.)",
        "arxiv_id": "2506.20260"
    }
}