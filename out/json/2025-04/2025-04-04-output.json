{
    "2504.02107": {
        "COMMENT": "Author match",
        "SCORE": 20.0,
        "authors": [
            "Jeffrey Li",
            "Mohammadreza Armandpour",
            "Iman Mirzadeh",
            "Sachin Mehta",
            "Vaishaal Shankar",
            "Raviteja Vemulapalli",
            "Samy Bengio",
            "Oncel Tuzel",
            "Mehrdad Farajtabar",
            "Hadi Pouransari",
            "Fartash Faghri"
        ],
        "title": "TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining",
        "abstract": "Large Language Models (LLMs) trained on historical web data inevitably become outdated. We investigate evaluation strategies and update methods for LLMs as new data becomes available. We introduce a web-scale dataset for time-continual pretraining of LLMs derived from 114 dumps of Common Crawl (CC) - orders of magnitude larger than previous continual language modeling benchmarks. We also design time-stratified evaluations across both general CC data and specific domains (Wikipedia, StackExchange, and code documentation) to assess how well various continual learning methods adapt to new data while retaining past knowledge. Our findings demonstrate that, on general CC data, autoregressive meta-schedules combined with a fixed-ratio replay of older data can achieve comparable held-out loss to re-training from scratch, while requiring significantly less computation (2.6x). However, the optimal balance between incorporating new data and replaying old data differs as replay is crucial to avoid forgetting on generic web data but less so on specific domains.",
        "arxiv_id": "2504.02107"
    },
    "2504.02658": {
        "SCORE": 19,
        "ARXIVID": "2504.02658",
        "COMMENT": "The paper addresses efficient quantization in Mixture-of-Experts (MoE) models, aligning closely with the 'Model Compression' and 'Model Architecture' criteria. It introduces low-rank compensators and adaptive rank selection policies, which are novel contributions.",
        "RELEVANCE": 10,
        "NOVELTY": 9,
        "authors": [
            "Beichen Huang",
            "Yueming Yuan",
            "Zelei Shao",
            "Minjia Zhang"
        ],
        "title": "MiLo: Efficient Quantized MoE Inference with Mixture of Low-Rank Compensators",
        "abstract": "A critical approach for efficiently deploying Mixture-of-Experts (MoE) models with massive parameters is quantization. However, state-of-the-art MoE models suffer from non-negligible accuracy loss with extreme quantization, such as under 4 bits. To address this, we introduce MiLo, a novel method that augments highly quantized MoEs with a mixture of low-rank compensators. These compensators consume only a small amount of additional memory but significantly recover accuracy loss from extreme quantization. MiLo also identifies that MoEmodels exhibit distinctive characteristics across weights due to their hybrid dense-sparse architectures, and employs adaptive rank selection policies along with iterative optimizations to close the accuracy gap. MiLo does not rely on calibration data, allowing it to generalize to different MoE models and datasets without overfitting to a calibration set. To avoid the hardware inefficiencies of extreme quantization, such as 3-bit, MiLo develops Tensor Core-friendly 3-bit kernels, enabling measured latency speedups on 3-bit quantized MoE models. Our evaluation shows that MiLo outperforms existing methods on SoTA MoE models across various tasks.",
        "arxiv_id": "2504.02658"
    },
    "2504.02058": {
        "SCORE": 19,
        "ARXIVID": "2504.02058",
        "COMMENT": "The paper introduces a theoretical model of epistemic closure and systemic barriers to alignment innovation, aligning with the 'Emerging Trends' criterion. It challenges established assumptions and proposes recursive modeling as a novel paradigm.",
        "RELEVANCE": 10,
        "NOVELTY": 9,
        "authors": [
            "Andy Williams"
        ],
        "title": "Epistemic Closure and the Irreversibility of Misalignment: Modeling Systemic Barriers to Alignment Innovation",
        "abstract": "Efforts to ensure the safe development of artificial general intelligence (AGI) often rely on consensus-based alignment approaches grounded in axiomatic formalism, interpretability, and empirical validation. However, these methods may be structurally unable to recognize or incorporate novel solutions that fall outside their accepted epistemic frameworks. This paper introduces a functional model of epistemic closure, in which cognitive, institutional, social, and infrastructural filters combine to make many alignment proposals illegible to existing evaluation systems. We present a weighted closure model supported by both theoretical and empirical sources, including a meta-analysis performed by an AI system on patterns of rejection and non-engagement with a framework for decentralized collective intelligence (DCI). We argue that the recursive failure to assess models like DCI is not just a sociological oversight but a structural attractor, mirroring the very risks of misalignment we aim to avoid in AGI. Without the adoption of DCI or a similarly recursive model of epistemic correction, we may be on a predictable path toward irreversible misalignment. The development and acceptance of this paper, first through simulated review and then through formal channels, provide a case study supporting its central claim: that epistemic closure can only be overcome by recursive modeling of the constraints that sustain it.",
        "arxiv_id": "2504.02058"
    },
    "2504.02170": {
        "SCORE": 18,
        "ARXIVID": "2504.02170",
        "COMMENT": "The paper introduces a novel algorithm (PL*) for learning regular languages using prefix queries, which is a cutting-edge theoretical contribution to representation learning and language modeling.",
        "RELEVANCE": 9,
        "NOVELTY": 9,
        "authors": [
            "Eve Fernando",
            "Sasha Rubin",
            "Rahul Gopinath"
        ],
        "title": "Example-Free Learning of Regular Languages with Prefix Queries",
        "abstract": "Language learning refers to the problem of inferring a mathematical model which accurately represents a formal language. Many language learning algorithms learn by asking certain types of queries about the language being modeled. Language learning is of practical interest in the field of cybersecurity, where it is used to model the language accepted by a program's input parser (also known as its input processor). In this setting, a learner can only query a string of its choice by executing the parser on it, which limits the language learning algorithms that can be used. Most practical parsers can indicate not only whether the string is valid or not, but also where the parsing failed. This extra information can be leveraged into producing a type of query we call the prefix query. Notably, no existing language learning algorithms make use of prefix queries, though some ask membership queries i.e., they ask whether or not a given string is valid. When these approaches are used to learn the language of a parser, the prefix information provided by the parser remains unused.   In this work, we present PL*, the first known language learning algorithm to make use of the prefix query, and a novel modification of the classical L* algorithm. We show both theoretically and empirically that PL* is able to learn more efficiently than L* due to its ability to exploit the additional information given by prefix queries over membership queries. Furthermore, we show how PL* can be used to learn the language of a parser, by adapting it to a more practical setting in which prefix queries are the only source of information available to it; that is, it does not have access to any labelled examples or any other types of queries. We demonstrate empirically that, even in this more constrained setting, PL* is still capable of accurately learning a range of languages of practical interest.",
        "arxiv_id": "2504.02170"
    },
    "2504.02459": {
        "SCORE": 17,
        "ARXIVID": "2504.02459",
        "COMMENT": "The paper introduces a physics-informed meta-learning framework for solving parametric PDEs, which aligns with 'AI for Science' due to its foundational contributions to computational mechanics and operator learning.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Reza Najian Asl",
            "Yusuke Yamazaki",
            "Kianoosh Taghikhani",
            "Mayu Muramatsu",
            "Markus Apel",
            "Shahed Rezaei"
        ],
        "title": "A Physics-Informed Meta-Learning Framework for the Continuous Solution of Parametric PDEs on Arbitrary Geometries",
        "abstract": "In this work, we introduce implicit Finite Operator Learning (iFOL) for the continuous and parametric solution of partial differential equations (PDEs) on arbitrary geometries. We propose a physics-informed encoder-decoder network to establish the mapping between continuous parameter and solution spaces. The decoder constructs the parametric solution field by leveraging an implicit neural field network conditioned on a latent or feature code. Instance-specific codes are derived through a PDE encoding process based on the second-order meta-learning technique. In training and inference, a physics-informed loss function is minimized during the PDE encoding and decoding. iFOL expresses the loss function in an energy or weighted residual form and evaluates it using discrete residuals derived from standard numerical PDE methods. This approach results in the backpropagation of discrete residuals during both training and inference.   iFOL features several key properties: (1) its unique loss formulation eliminates the need for the conventional encode-process-decode pipeline previously used in operator learning with conditional neural fields for PDEs; (2) it not only provides accurate parametric and continuous fields but also delivers solution-to-parameter gradients without requiring additional loss terms or sensitivity analysis; (3) it can effectively capture sharp discontinuities in the solution; and (4) it removes constraints on the geometry and mesh, making it applicable to arbitrary geometries and spatial sampling (zero-shot super-resolution capability). We critically assess these features and analyze the network's ability to generalize to unseen samples across both stationary and transient PDEs. The overall performance of the proposed method is promising, demonstrating its applicability to a range of challenging problems in computational mechanics.",
        "arxiv_id": "2504.02459"
    },
    "2504.02822": {
        "SCORE": 17,
        "ARXIVID": "2504.02822",
        "COMMENT": "This paper explores how AI models converge on theories in scientific tasks, using Hamiltonian-Lagrangian neural networks. It aligns with 'Emerging Trends' as it challenges assumptions about AI learning dynamics and introduces a novel perspective on interpretability in scientific modeling.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Xinghong Fu",
            "Ziming Liu",
            "Max Tegmark"
        ],
        "title": "Do Two AI Scientists Agree?",
        "abstract": "When two AI models are trained on the same scientific task, do they learn the same theory or two different theories? Throughout history of science, we have witnessed the rise and fall of theories driven by experimental validation or falsification: many theories may co-exist when experimental data is lacking, but the space of survived theories become more constrained with more experimental data becoming available. We show the same story is true for AI scientists. With increasingly more systems provided in training data, AI scientists tend to converge in the theories they learned, although sometimes they form distinct groups corresponding to different theories. To mechanistically interpret what theories AI scientists learn and quantify their agreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI Scientists, trained on standard problems in physics, aggregating training results across many seeds simulating the different configurations of AI scientists. Our findings suggests for AI scientists switch from learning a Hamiltonian theory in simple setups to a Lagrangian formulation when more complex systems are introduced. We also observe strong seed dependence of the training dynamics and final learned weights, controlling the rise and fall of relevant theories. We finally demonstrate that not only can our neural networks aid interpretability, it can also be applied to higher dimensional problems.",
        "arxiv_id": "2504.02822"
    },
    "2504.02511": {
        "SCORE": 17,
        "ARXIVID": "2504.02511",
        "COMMENT": "The paper introduces GAMLA, a framework for analytical manifold learning using autoencoders, aligning with the 'Representation Learning' criterion. It provides foundational insights into manifold geometry and interpretability.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Yafei Shen",
            "Huan-Fei Ma",
            "Ling Yang"
        ],
        "title": "Analytical Discovery of Manifold with Machine Learning",
        "abstract": "Understanding low-dimensional structures within high-dimensional data is crucial for visualization, interpretation, and denoising in complex datasets. Despite the advancements in manifold learning techniques, key challenges-such as limited global insight and the lack of interpretable analytical descriptions-remain unresolved. In this work, we introduce a novel framework, GAMLA (Global Analytical Manifold Learning using Auto-encoding). GAMLA employs a two-round training process within an auto-encoding framework to derive both character and complementary representations for the underlying manifold. With the character representation, the manifold is represented by a parametric function which unfold the manifold to provide a global coordinate. While with the complementary representation, an approximate explicit manifold description is developed, offering a global and analytical representation of smooth manifolds underlying high-dimensional datasets. This enables the analytical derivation of geometric properties such as curvature and normal vectors. Moreover, we find the two representations together decompose the whole latent space and can thus characterize the local spatial structure surrounding the manifold, proving particularly effective in anomaly detection and categorization. Through extensive experiments on benchmark datasets and real-world applications, GAMLA demonstrates its ability to achieve computational efficiency and interpretability while providing precise geometric and structural insights. This framework bridges the gap between data-driven manifold learning and analytical geometry, presenting a versatile tool for exploring the intrinsic properties of complex data sets.",
        "arxiv_id": "2504.02511"
    },
    "2504.02821": {
        "SCORE": 17,
        "ARXIVID": "2504.02821",
        "COMMENT": "The paper applies Sparse Autoencoders (SAEs) to Vision-Language Models (VLMs), enhancing interpretability and control, which aligns with the 'Representation Learning' criterion. It also contributes to unsupervised methods for improving model behavior.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Mateusz Pach",
            "Shyamgopal Karthik",
            "Quentin Bouniot",
            "Serge Belongie",
            "Zeynep Akata"
        ],
        "title": "Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models",
        "abstract": "Sparse Autoencoders (SAEs) have recently been shown to enhance interpretability and steerability in Large Language Models (LLMs). In this work, we extend the application of SAEs to Vision-Language Models (VLMs), such as CLIP, and introduce a comprehensive framework for evaluating monosemanticity in vision representations. Our experimental results reveal that SAEs trained on VLMs significantly enhance the monosemanticity of individual neurons while also exhibiting hierarchical representations that align well with expert-defined structures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that applying SAEs to intervene on a CLIP vision encoder, directly steer output from multimodal LLMs (e.g., LLaVA) without any modifications to the underlying model. These findings emphasize the practicality and efficacy of SAEs as an unsupervised approach for enhancing both the interpretability and control of VLMs.",
        "arxiv_id": "2504.02821"
    },
    "2504.02263": {
        "SCORE": 17,
        "ARXIVID": "2504.02263",
        "COMMENT": "This paper focuses on optimizing Mixture-of-Experts (MoE) inference with disaggregated parallelism and introduces novel techniques like ping-pong pipeline parallelism. It aligns closely with the 'Model Architecture' criterion for MoE innovations.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Ruidong Zhu",
            "Ziheng Jiang",
            "Chao Jin",
            "Peng Wu",
            "Cesar A. Stuardo",
            "Dongyang Wang",
            "Xinlei Zhang",
            "Huaping Zhou",
            "Haoran Wei",
            "Yang Cheng",
            "Jianzhe Xiao",
            "Xinyi Zhang",
            "Lingjun Liu",
            "Haibin Lin",
            "Li-Wen Chang",
            "Jianxi Ye",
            "Xiao Yu",
            "Xuanzhe Liu",
            "Xin Jin",
            "Xin Liu"
        ],
        "title": "MegaScale-Infer: Serving Mixture-of-Experts at Scale with Disaggregated Expert Parallelism",
        "abstract": "Mixture-of-Experts (MoE) showcases tremendous potential to scale large language models (LLMs) with enhanced performance and reduced computational complexity. However, its sparsely activated architecture shifts feed-forward networks (FFNs) from being compute-intensive to memory-intensive during inference, leading to substantially lower GPU utilization and increased operational costs. We present MegaScale-Infer, an efficient and cost-effective system for serving large-scale MoE models. MegaScale-Infer disaggregates attention and FFN modules within each model layer, enabling independent scaling, tailored parallelism strategies, and heterogeneous deployment for both modules. To fully exploit disaggregation in the presence of MoE's sparsity, MegaScale-Infer introduces ping-pong pipeline parallelism, which partitions a request batch into micro-batches and shuttles them between attention and FFNs for inference. Combined with distinct model parallelism for each module, MegaScale-Infer effectively hides communication overhead and maximizes GPU utilization. To adapt to disaggregated attention and FFN modules and minimize data transmission overhead (e.g., token dispatch), MegaScale-Infer provides a high-performance M2N communication library that eliminates unnecessary GPU-to-CPU data copies, group initialization overhead, and GPU synchronization. Experimental results indicate that MegaScale-Infer achieves up to 1.90x higher per-GPU throughput than state-of-the-art solutions.",
        "arxiv_id": "2504.02263"
    },
    "2504.02168": {
        "SCORE": 17,
        "ARXIVID": "2504.02168",
        "COMMENT": "The paper introduces a novel multi-dimensional pruning framework for both CNNs and transformers, addressing latency constraints and achieving significant efficiency improvements. This aligns well with the 'Model Compression' criterion.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Xinglong Sun",
            "Barath Lakshmanan",
            "Maying Shen",
            "Shiyi Lan",
            "Jingde Chen",
            "Jose M. Alvarez"
        ],
        "title": "MDP: Multidimensional Vision Model Pruning with Latency Constraint",
        "abstract": "Current structural pruning methods face two significant limitations: (i) they often limit pruning to finer-grained levels like channels, making aggressive parameter reduction challenging, and (ii) they focus heavily on parameter and FLOP reduction, with existing latency-aware methods frequently relying on simplistic, suboptimal linear models that fail to generalize well to transformers, where multiple interacting dimensions impact latency. In this paper, we address both limitations by introducing Multi-Dimensional Pruning (MDP), a novel paradigm that jointly optimizes across a variety of pruning granularities-including channels, query, key, heads, embeddings, and blocks. MDP employs an advanced latency modeling technique to accurately capture latency variations across all prunable dimensions, achieving an optimal balance between latency and accuracy. By reformulating pruning as a Mixed-Integer Nonlinear Program (MINLP), MDP efficiently identifies the optimal pruned structure across all prunable dimensions while respecting latency constraints. This versatile framework supports both CNNs and transformers. Extensive experiments demonstrate that MDP significantly outperforms previous methods, especially at high pruning ratios. On ImageNet, MDP achieves a 28% speed increase with a +1.4 Top-1 accuracy improvement over prior work like HALP for ResNet50 pruning. Against the latest transformer pruning method, Isomorphic, MDP delivers an additional 37% acceleration with a +0.7 Top-1 accuracy improvement.",
        "arxiv_id": "2504.02168"
    },
    "2504.02692": {
        "SCORE": 17,
        "ARXIVID": "2504.02692",
        "COMMENT": "The paper introduces GPTQv2, a finetuning-free quantization method for large-scale transformers, which aligns strongly with the 'Model Compression' criterion, particularly in quantization and efficiency improvements.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Yuhang Li",
            "Ruokai Yin",
            "Donghyun Lee",
            "Shiting Xiao",
            "Priyadarshini Panda"
        ],
        "title": "GPTQv2: Efficient Finetuning-Free Quantization for Asymmetric Calibration",
        "abstract": "We introduce GPTQv2, a novel finetuning-free quantization method for compressing large-scale transformer architectures. Unlike the previous GPTQ method, which independently calibrates each layer, we always match the quantized layer's output to the exact output in the full-precision model, resulting in a scheme that we call asymmetric calibration. Such a scheme can effectively reduce the quantization error accumulated in previous layers. We analyze this problem using optimal brain compression to derive a close-formed solution. The new solution explicitly minimizes the quantization error as well as the accumulated asymmetry error. Furthermore, we utilize various techniques to parallelize the solution calculation, including channel parallelization, neuron decomposition, and Cholesky reformulation for matrix fusion. As a result, GPTQv2 is easy to implement, simply using 20 more lines of code than GPTQ but improving its performance under low-bit quantization. Remarkably, on a single GPU, we quantize a 405B language transformer as well as EVA-02 the rank first vision transformer that achieves 90% pretraining Imagenet accuracy. Code is available at github.com/Intelligent-Computing-Lab-Yale/GPTQv2.",
        "arxiv_id": "2504.02692"
    },
    "2504.02349": {
        "SCORE": 17,
        "ARXIVID": "2504.02349",
        "COMMENT": "The paper explores unsupervised adaptation methods for large language models, focusing on foundational aspects of in-context learning and joint inference, which aligns with the LLM criterion.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Artyom Gadetsky",
            "Andrei Atanov",
            "Yulun Jiang",
            "Zhitong Gao",
            "Ghazal Hosseini Mighan",
            "Amir Zamir",
            "Maria Brbic"
        ],
        "title": "Large (Vision) Language Models are Unsupervised In-Context Learners",
        "abstract": "Recent advances in large language and vision-language models have enabled zero-shot inference, allowing models to solve new tasks without task-specific training. Various adaptation techniques such as prompt engineering, In-Context Learning (ICL), and supervised fine-tuning can further enhance the model's performance on a downstream task, but they require substantial manual effort to construct effective prompts or labeled examples. In this work, we introduce a joint inference framework for fully unsupervised adaptation, eliminating the need for manual prompt engineering and labeled examples. Unlike zero-shot inference, which makes independent predictions, the joint inference makes predictions simultaneously for all inputs in a given task. Since direct joint inference involves computationally expensive optimization, we develop efficient approximation techniques, leading to two unsupervised adaptation methods: unsupervised fine-tuning and unsupervised ICL. We demonstrate the effectiveness of our methods across diverse tasks and models, including language-only Llama-3.1 on natural language processing tasks, reasoning-oriented Qwen2.5-Math on grade school math problems, vision-language OpenFlamingo on vision tasks, and the API-only access GPT-4o model on massive multi-discipline tasks. Our experiments demonstrate substantial improvements over the standard zero-shot approach, including 39% absolute improvement on the challenging GSM8K math reasoning dataset. Remarkably, despite being fully unsupervised, our framework often performs on par with supervised approaches that rely on ground truth labels.",
        "arxiv_id": "2504.02349"
    },
    "2504.02618": {
        "SCORE": 17,
        "ARXIVID": "2504.02618",
        "COMMENT": "The paper introduces a novel variational online mirror descent framework for Schr\u00f6dinger Bridge problems, which is a foundational contribution to probabilistic generative modeling. It aligns with 'Emerging Trends' due to its theoretical advancements.",
        "RELEVANCE": 8,
        "NOVELTY": 9,
        "authors": [
            "Dong-Sig Han",
            "Jaein Kim",
            "Hee Bin Yoo",
            "Byoung-Tak Zhang"
        ],
        "title": "Variational Online Mirror Descent for Robust Learning in Schr\\\"odinger Bridge",
        "abstract": "Sch\\\"odinger bridge (SB) has evolved into a universal class of probabilistic generative models. In practice, however, estimated learning signals are often uncertain, and the reliability promised by existing methods is often based on speculative optimal-case scenarios. Recent studies regarding the Sinkhorn algorithm through mirror descent (MD) have gained attention, revealing geometric insights into solution acquisition of the SB problems. In this paper, we propose a variational online MD (OMD) framework for the SB problems, which provides further stability to SB solvers. We formally prove convergence and a regret bound for the novel OMD formulation of SB acquisition. As a result, we propose a simulation-free SB algorithm called Variational Mirrored Schr\\\"odinger Bridge (VMSB) by utilizing the Wasserstein-Fisher-Rao geometry of the Gaussian mixture parameterization for Schr\\\"odinger potentials. Based on the Wasserstein gradient flow theory, the algorithm offers tractable learning dynamics that precisely approximate each OMD step. In experiments, we validate the performance of the proposed VMSB algorithm across an extensive suite of benchmarks. VMSB consistently outperforms contemporary SB solvers on a range of SB problems, demonstrating the robustness predicted by our theory.",
        "arxiv_id": "2504.02618"
    },
    "2504.02010": {
        "SCORE": 16,
        "ARXIVID": "2504.02010",
        "COMMENT": "The paper benchmarks compressed large reasoning models, providing insights into compression techniques like quantization, pruning, and distillation. It aligns with foundational research in model compression and efficiency.",
        "RELEVANCE": 9,
        "NOVELTY": 7,
        "authors": [
            "Nan Zhang",
            "Yusen Zhang",
            "Prasenjit Mitra",
            "Rui Zhang"
        ],
        "title": "When Reasoning Meets Compression: Benchmarking Compressed Large Reasoning Models on Complex Reasoning Tasks",
        "abstract": "Recent open-source large reasoning models (LRMs) exhibit strong performance on complex reasoning tasks, but their large parameter count makes them prohibitively expensive for individuals. The compression of large language models (LLMs) offers an effective solution to reduce cost of computational resources. However, systematic studies on the performance of compressed LLMs in complex reasoning tasks, especially for LRMs, are lacking. Most works on quantization and pruning focus on preserving language modeling performance, while existing distillation works do not comprehensively benchmark student models based on reasoning difficulty or compression impact on knowledge and reasoning. In this paper, we benchmark compressed DeepSeek-R1 models on four different reasoning datasets (AIME 2024, FOLIO, Temporal Sequences of BIG-Bench Hard, and MuSiQue), ranging from mathematical to multihop reasoning, using quantization, distillation, and pruning methods. We benchmark 2.51-, 1.73-, and 1.58-bit R1 models that adopt dynamic quantization. We also benchmark distilled R1 models that are based on LLaMA or Qwen and run SparseGPT on them to obtain various sparsity levels. Studying the performance and behavior of compressed LRMs, we report their performance scores and test-time compute (number of tokens spent on each question). Notably, using MuSiQue, we find that parameter count has a much greater impact on LRMs' knowledge memorization than on their reasoning capability, which can inform the choice of compression techniques. Through our empirical analysis of test-time compute, we find that shorter model outputs generally achieve better performance than longer ones across several benchmarks for both R1 and its compressed variants, highlighting the need for more concise reasoning chains.",
        "arxiv_id": "2504.02010"
    },
    "2504.02260": {
        "SCORE": 16,
        "ARXIVID": "2504.02260",
        "COMMENT": "The paper introduces a novel implicit neural differential model for spatiotemporal dynamics, which aligns with foundational research in model architecture and training dynamics. The use of implicit fixed-point layers and hybrid gradient propagation strategy is innovative.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Deepak Akhare",
            "Pan Du",
            "Tengfei Luo",
            "Jian-Xun Wang"
        ],
        "title": "Implicit Neural Differential Model for Spatiotemporal Dynamics",
        "abstract": "Hybrid neural-physics modeling frameworks through differentiable programming have emerged as powerful tools in scientific machine learning, enabling the integration of known physics with data-driven learning to improve prediction accuracy and generalizability. However, most existing hybrid frameworks rely on explicit recurrent formulations, which suffer from numerical instability and error accumulation during long-horizon forecasting. In this work, we introduce Im-PiNDiff, a novel implicit physics-integrated neural differentiable solver for stable and accurate modeling of spatiotemporal dynamics. Inspired by deep equilibrium models, Im-PiNDiff advances the state using implicit fixed-point layers, enabling robust long-term simulation while remaining fully end-to-end differentiable. To enable scalable training, we introduce a hybrid gradient propagation strategy that integrates adjoint-state methods with reverse-mode automatic differentiation. This approach eliminates the need to store intermediate solver states and decouples memory complexity from the number of solver iterations, significantly reducing training overhead. We further incorporate checkpointing techniques to manage memory in long-horizon rollouts. Numerical experiments on various spatiotemporal PDE systems, including advection-diffusion processes, Burgers' dynamics, and multi-physics chemical vapor infiltration processes, demonstrate that Im-PiNDiff achieves superior predictive performance, enhanced numerical stability, and substantial reductions in memory and runtime cost relative to explicit and naive implicit baselines. This work provides a principled, efficient, and scalable framework for hybrid neural-physics modeling.",
        "arxiv_id": "2504.02260"
    },
    "2504.01990": {
        "SCORE": 16,
        "ARXIVID": "2504.01990",
        "COMMENT": "The survey provides a modular, brain-inspired architecture for intelligent agents, touching on foundational aspects of memory, world modeling, and continual learning. It aligns with emerging trends and foundational research in LLMs and AI systems.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Bang Liu",
            "Xinfeng Li",
            "Jiayi Zhang",
            "Jinlin Wang",
            "Tanjin He",
            "Sirui Hong",
            "Hongzhang Liu",
            "Shaokun Zhang",
            "Kaitao Song",
            "Kunlun Zhu",
            "Yuheng Cheng",
            "Suyuchen Wang",
            "Xiaoqiang Wang",
            "Yuyu Luo",
            "Haibo Jin",
            "Peiyan Zhang",
            "Ollie Liu",
            "Jiaqi Chen",
            "Huan Zhang",
            "Zhaoyang Yu",
            "Haochen Shi",
            "Boyan Li",
            "Dekun Wu",
            "Fengwei Teng",
            "Xiaojun Jia",
            "Jiawei Xu",
            "Jinyu Xiang",
            "Yizhang Lin",
            "Tianming Liu",
            "Tongliang Liu",
            "Yu Su",
            "Huan Sun",
            "Glen Berseth",
            "Jianyun Nie",
            "Ian Foster",
            "Logan Ward",
            "Qingyun Wu",
            "Yu Gu",
            "Mingchen Zhuge",
            "Xiangru Tang",
            "Haohan Wang",
            "Jiaxuan You",
            "Chi Wang",
            "Jian Pei",
            "Qiang Yang",
            "Xiaoliang Qi",
            "Chenglin Wu"
        ],
        "title": "Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems",
        "abstract": "The advent of large language models (LLMs) has catalyzed a transformative shift in artificial intelligence, paving the way for advanced intelligent agents capable of sophisticated reasoning, robust perception, and versatile action across diverse domains. As these agents increasingly drive AI research and practical applications, their design, evaluation, and continuous improvement present intricate, multifaceted challenges. This survey provides a comprehensive overview, framing intelligent agents within a modular, brain-inspired architecture that integrates principles from cognitive science, neuroscience, and computational research. We structure our exploration into four interconnected parts. First, we delve into the modular foundation of intelligent agents, systematically mapping their cognitive, perceptual, and operational modules onto analogous human brain functionalities, and elucidating core components such as memory, world modeling, reward processing, and emotion-like systems. Second, we discuss self-enhancement and adaptive evolution mechanisms, exploring how agents autonomously refine their capabilities, adapt to dynamic environments, and achieve continual learning through automated optimization paradigms, including emerging AutoML and LLM-driven optimization strategies. Third, we examine collaborative and evolutionary multi-agent systems, investigating the collective intelligence emerging from agent interactions, cooperation, and societal structures, highlighting parallels to human social dynamics. Finally, we address the critical imperative of building safe, secure, and beneficial AI systems, emphasizing intrinsic and extrinsic security threats, ethical alignment, robustness, and practical mitigation strategies necessary for trustworthy real-world deployment.",
        "arxiv_id": "2504.01990"
    },
    "2504.02211": {
        "SCORE": 16,
        "ARXIVID": "2504.02211",
        "COMMENT": "The paper introduces a novel fault-tolerant framework for Transformers, which aligns with the 'Model Architecture' criterion by addressing architectural reliability and efficiency. The proposed methods, such as architecture-aware ABFT and selective neuron value restriction, are innovative.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Huangliang Dai",
            "Shixun Wu",
            "Hairui Zhao",
            "Jiajun Huang",
            "Zizhe Jian",
            "Yue Zhu",
            "Haiyang Hu",
            "Zizhong Chen"
        ],
        "title": "FT-Transformer: Resilient and Reliable Transformer with End-to-End Fault Tolerant Attention",
        "abstract": "Transformer models leverage self-attention mechanisms to capture complex dependencies, demonstrating exceptional performance in various applications. However, the long-duration high-load computations required for model inference impose stringent reliability demands on the computing platform, as soft errors that occur during execution can significantly degrade model performance. Existing fault tolerance methods protect each operation separately using decoupled kernels, incurring substantial computational and memory overhead. In this paper, we propose a novel error-resilient framework for Transformer models, integrating end-to-end fault tolerant attention (EFTA) to improve inference reliability against soft errors. Our approach enables error detection and correction within a fully fused attention kernel, reducing redundant data access and thereby mitigating memory faults. To further enhance error coverage and reduce overhead, we design a hybrid fault tolerance scheme tailored for the EFTA, introducing for the first time: 1) architecture-aware algorithm-based fault tolerance (ABFT) using tensor checksum, which minimizes inter-thread communication overhead on tensor cores during error detection; 2) selective neuron value restriction, which selectively applies adaptive fault tolerance constraints to neuron values, balancing error coverage and overhead; 3) unified verification, reusing checksums to streamline multiple computation steps into a single verification process. Experimental results show that EFTA achieves up to 7.56x speedup over traditional methods with an average fault tolerance overhead of 13.9%.",
        "arxiv_id": "2504.02211"
    },
    "2504.02819": {
        "SCORE": 16,
        "ARXIVID": "2504.02819",
        "COMMENT": "The paper proposes GMR-Conv, a novel convolution kernel with rotation and reflection equivariance, which aligns with architectural innovations in equivariant networks.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Yuexi Du",
            "Jiazhen Zhang",
            "Nicha C. Dvornek",
            "John A. Onofrey"
        ],
        "title": "GMR-Conv: An Efficient Rotation and Reflection Equivariant Convolution Kernel Using Gaussian Mixture Rings",
        "abstract": "Symmetry, where certain features remain invariant under geometric transformations, can often serve as a powerful prior in designing convolutional neural networks (CNNs). While conventional CNNs inherently support translational equivariance, extending this property to rotation and reflection has proven challenging, often forcing a compromise between equivariance, efficiency, and information loss. In this work, we introduce Gaussian Mixture Ring Convolution (GMR-Conv), an efficient convolution kernel that smooths radial symmetry using a mixture of Gaussian-weighted rings. This design mitigates discretization errors of circular kernels, thereby preserving robust rotation and reflection equivariance without incurring computational overhead. We further optimize both the space and speed efficiency of GMR-Conv via a novel parameterization and computation strategy, allowing larger kernels at an acceptable cost. Extensive experiments on eight classification and one segmentation datasets demonstrate that GMR-Conv not only matches conventional CNNs' performance but can also surpass it in applications with orientation-less data. GMR-Conv is also proven to be more robust and efficient than the state-of-the-art equivariant learning methods. Our work provides inspiring empirical evidence that carefully applied radial symmetry can alleviate the challenges of information loss, marking a promising advance in equivariant network architectures. The code is available at https://github.com/XYPB/GMR-Conv.",
        "arxiv_id": "2504.02819"
    },
    "2504.02144": {
        "SCORE": 15,
        "ARXIVID": "2504.02144",
        "COMMENT": "The paper introduces a theoretical framework for interpretable soft prompts, aligning with 'Representation Learning' and 'Large Language Models' as it addresses interpretability and optimization in trainable prompts.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Oam Patel",
            "Jason Wang",
            "Nikhil Shivakumar Nayak",
            "Suraj Srinivas",
            "Himabindu Lakkaraju"
        ],
        "title": "Towards Interpretable Soft Prompts",
        "abstract": "Soft prompts have been popularized as a cheap and easy way to improve task-specific LLM performance beyond few-shot prompts. Despite their origin as an automated prompting method, however, soft prompts and other trainable prompts remain a black-box method with no immediately interpretable connections to prompting. We create a novel theoretical framework for evaluating the interpretability of trainable prompts based on two desiderata: faithfulness and scrutability. We find that existing methods do not naturally satisfy our proposed interpretability criterion. Instead, our framework inspires a new direction of trainable prompting methods that explicitly optimizes for interpretability. To this end, we formulate and test new interpretability-oriented objective functions for two state-of-the-art prompt tuners: Hard Prompts Made Easy (PEZ) and RLPrompt. Our experiments with GPT-2 demonstrate a fundamental trade-off between interpretability and the task-performance of the trainable prompt, explicating the hardness of the soft prompt interpretability problem and revealing odd behavior that arises when one optimizes for an interpretability proxy.",
        "arxiv_id": "2504.02144"
    },
    "2504.02591": {
        "SCORE": 15,
        "ARXIVID": "2504.02591",
        "COMMENT": "The paper proposes a novel MIMO spiking neuron model inspired by state-space models, which introduces architectural innovations in spiking neural networks. This aligns with the 'Model Architecture' criterion.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Sanja Karilanova",
            "Subhrakanti Dey",
            "Ay\\c{c}a \\\"Oz\\c{c}elikkale"
        ],
        "title": "State-Space Model Inspired Multiple-Input Multiple-Output Spiking Neurons",
        "abstract": "In spiking neural networks (SNNs), the main unit of information processing is the neuron with an internal state. The internal state generates an output spike based on its component associated with the membrane potential. This spike is then communicated to other neurons in the network. Here, we propose a general multiple-input multiple-output (MIMO) spiking neuron model that goes beyond this traditional single-input single-output (SISO) model in the SNN literature. Our proposed framework is based on interpreting the neurons as state-space models (SSMs) with linear state evolutions and non-linear spiking activation functions. We illustrate the trade-offs among various parameters of the proposed SSM-inspired neuron model, such as the number of hidden neuron states, the number of input and output channels, including single-input multiple-output (SIMO) and multiple-input single-output (MISO) models. We show that for SNNs with a small number of neurons with large internal state spaces, significant performance gains may be obtained by increasing the number of output channels of a neuron. In particular, a network with spiking neurons with multiple-output channels may achieve the same level of accuracy with the baseline with the continuous-valued communications on the same reference network architecture.",
        "arxiv_id": "2504.02591"
    },
    "2504.02607": {
        "SCORE": 15,
        "ARXIVID": "2504.02607",
        "COMMENT": "The paper introduces a novel diffeomorphic function learning framework with RBF networks, which aligns with representation learning through indirect function approximation and structural encoding.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Samuel Tesfazgi",
            "Leonhard Sprandl",
            "Sandra Hirche"
        ],
        "title": "Learning Geometrically-Informed Lyapunov Functions with Deep Diffeomorphic RBF Networks",
        "abstract": "The practical deployment of learning-based autonomous systems would greatly benefit from tools that flexibly obtain safety guarantees in the form of certificate functions from data. While the geometrical properties of such certificate functions are well understood, synthesizing them using machine learning techniques still remains a challenge. To mitigate this issue, we propose a diffeomorphic function learning framework where prior structural knowledge of the desired output is encoded in the geometry of a simple surrogate function, which is subsequently augmented through an expressive, topology-preserving state-space transformation. Thereby, we achieve an indirect function approximation framework that is guaranteed to remain in the desired hypothesis space. To this end, we introduce a novel approach to construct diffeomorphic maps based on RBF networks, which facilitate precise, local transformations around data. Finally, we demonstrate our approach by learning diffeomorphic Lyapunov functions from real-world data and apply our method to different attractor systems.",
        "arxiv_id": "2504.02607"
    },
    "2504.02016": {
        "SCORE": 15,
        "ARXIVID": "2504.02016",
        "COMMENT": "The paper proposes a Fourier feature attribution method, which provides insights into representation learning by analyzing neural networks through signal decomposition theory.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Zechen Liu",
            "Feiyang Zhang",
            "Wei Song",
            "Xiang Li",
            "Wei Wei"
        ],
        "title": "Fourier Feature Attribution: A New Efficiency Attribution Method",
        "abstract": "The study of neural networks from the perspective of Fourier features has garnered significant attention. While existing analytical research suggests that neural networks tend to learn low-frequency features, a clear attribution method for identifying the specific learned Fourier features has remained elusive. To bridge this gap, we propose a novel Fourier feature attribution method grounded in signal decomposition theory. Additionally, we analyze the differences between game-theoretic attribution metrics for Fourier and spatial domain features, demonstrating that game-theoretic evaluation metrics are better suited for Fourier-based feature attribution.   Our experiments show that Fourier feature attribution exhibits superior feature selection capabilities compared to spatial domain attribution methods. For instance, in the case of Vision Transformers (ViTs) on the ImageNet dataset, only $8\\%$ of the Fourier features are required to maintain the original predictions for $80\\%$ of the samples. Furthermore, we compare the specificity of features identified by our method against traditional spatial domain attribution methods. Results reveal that Fourier features exhibit greater intra-class concentration and inter-class distinctiveness, indicating their potential for more efficient classification and explainable AI algorithms.",
        "arxiv_id": "2504.02016"
    },
    "2504.02620": {
        "SCORE": 15,
        "ARXIVID": "2504.02620",
        "COMMENT": "The paper introduces sparse fine-tuning for task-localized model editing, which aligns with model compression and efficiency breakthroughs.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Leonardo Iurada",
            "Marco Ciccone",
            "Tatiana Tommasi"
        ],
        "title": "Efficient Model Editing with Task-Localized Sparse Fine-tuning",
        "abstract": "Task arithmetic has emerged as a promising approach for editing models by representing task-specific knowledge as composable task vectors. However, existing methods rely on network linearization to derive task vectors, leading to computational bottlenecks during training and inference. Moreover, linearization alone does not ensure weight disentanglement, the key property that enables conflict-free composition of task vectors. To address this, we propose TaLoS which allows to build sparse task vectors with minimal interference without requiring explicit linearization and sharing information across tasks. We find that pre-trained models contain a subset of parameters with consistently low gradient sensitivity across tasks, and that sparsely updating only these parameters allows for promoting weight disentanglement during fine-tuning. Our experiments prove that TaLoS improves training and inference efficiency while outperforming current methods in task addition and negation. By enabling modular parameter editing, our approach fosters practical deployment of adaptable foundation models in real-world applications.",
        "arxiv_id": "2504.02620"
    }
}