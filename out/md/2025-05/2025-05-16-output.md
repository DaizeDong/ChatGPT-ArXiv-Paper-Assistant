> This is a remedial run for missed papers from 05/15/2025 to 05/15/2025.
> 
> Results generated on 05/26/2025.

# Personalized Daily ArXiv Papers 2025-05-16

| *[gpt-4o]*   | Prompt   | Completion   | Total   |
|:------------:|:--------:|:------------:|:-------:|
| **Token**    | 23827    | 2914         | 26741   |
| **Cost**     | $0.06    | $0.03        | $0.09   |

Total arXiv papers: 262

Total scanned papers: 262

Total relevant papers: 11

**Table of contents with paper titles:**

1. [A probabilistic framework for dynamic quantization](#user-content-link1)
**Authors:** Gabriele Santini, Francesco Paissan, Elisabetta Farella

2. [Parallel Scaling Law for Language Models](#user-content-link2)
**Authors:** Mouxiang Chen, Binyuan Hui, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Jianling Sun, Junyang Lin, Zhongxin Liu

3. [Neural Thermodynamic Laws for Large Language Model Training](#user-content-link3)
**Authors:** Ziming Liu, Yizhou Liu, Jeff Gore, Max Tegmark

4. [Superposition Yields Robust Neural Scaling](#user-content-link4)
**Authors:** Yizhou Liu, Ziming Liu, Jeff Gore

5. [Learning Repetition-Invariant Representations for Polymer Informatics](#user-content-link5)
**Authors:** Yihan Zhu, Gang Liu, Eric Inae, Tengfei Luo, Meng Jiang

6. [FlowVAT: Normalizing Flow Variational Inference with Affine-Invariant Tempering](#user-content-link6)
**Authors:** Juehang Qin, Shixiao Liang, Christopher Tunnell

7. [Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates](#user-content-link7)
**Authors:** Hang Chen, Jiaying Zhu, Xinyu Yang, Wenya Wang

8. [The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think](#user-content-link8)
**Authors:** Seongyun Lee, Seungone Kim, Minju Seo, Yongrae Jo, Dongyoung Go, Hyeonbin Hwang, Jinho Park, Xiang Yue, Sean Welleck, Graham Neubig, Moontae Lee, Minjoon Seo

9. [ZEUS: Zero-shot Embeddings for Unsupervised Separation of Tabular Data](#user-content-link9)
**Authors:** Patryk Marszałek, Tomasz Kuśmierczyk, Witold Wydmański, Jacek Tabor, Marek Śmieja

10. [SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\mathcal{O}(T)$ Complexity](#user-content-link10)
**Authors:** Shihao Zou, Qingfeng Li, Wei Ji, Jingjing Li, Yongkui Yang, Guoqi Li, Chao Dong

11. [Emergence of Structure in Ensembles of Random Neural Networks](#user-content-link11)
**Authors:** Luca Muscarnera, Luigi Loreti, Giovanni Todeschini, Alessio Fumagalli, Francesco Regazzoni

---

## 1. [A probabilistic framework for dynamic quantization](https://arxiv.org/abs/2505.10689) <a id="link1"></a>

**ArXiv ID:** 2505.10689

**Authors:** Gabriele Santini, Francesco Paissan, Elisabetta Farella

**Abstract:** We propose a probabilistic framework for dynamic quantization of neural networks that allows for a computationally efficient input-adaptive rescaling of the quantization parameters. Our framework applies a probabilistic model to the network's pre-activations through a lightweight surrogate, enabling the adaptive adjustment of the quantization parameters on a per-input basis without significant memory overhead. We validate our approach on a set of popular computer vision tasks and models, observing only a negligible loss in performance. Our method strikes the best performance and computational overhead tradeoff compared to standard quantization strategies.

**Comment:** The paper proposes a probabilistic framework for dynamic quantization, which is relevant to model compression by introducing an input-adaptive rescaling method.

**Relevance:** 9
**Novelty:** 8

---

## 2. [Parallel Scaling Law for Language Models](https://arxiv.org/abs/2505.10475) <a id="link2"></a>

**ArXiv ID:** 2505.10475

**Authors:** Mouxiang Chen, Binyuan Hui, Zeyu Cui, Jiaxi Yang, Dayiheng Liu, Jianling Sun, Junyang Lin, Zhongxin Liu

**Abstract:** It is commonly believed that scaling language models should commit a significant space or time cost, by increasing the parameters (parameter scaling) or output tokens (inference-time scaling). We introduce the third and more inference-efficient scaling paradigm: increasing the model's parallel computation during both training and inference time. We apply $P$ diverse and learnable transformations to the input, execute forward passes of the model in parallel, and dynamically aggregate the $P$ outputs. This method, namely parallel scaling (ParScale), scales parallel computation by reusing existing parameters and can be applied to any model structure, optimization procedure, data, or task. We theoretically propose a new scaling law and validate it through large-scale pre-training, which shows that a model with $P$ parallel streams is similar to scaling the parameters by $O(\log P)$ while showing superior inference efficiency. For example, ParScale can use up to 22$\times$ less memory increase and 6$\times$ less latency increase compared to parameter scaling that achieves the same performance improvement. It can also recycle an off-the-shelf pre-trained model into a parallelly scaled one by post-training on a small amount of tokens, further reducing the training budget. The new scaling law we discovered potentially facilitates the deployment of more powerful models in low-resource scenarios, and provides an alternative perspective for the role of computation in machine learning.

**Comment:** The paper introduces a new scaling paradigm for language models, which aligns with the interest in model architecture and efficiency improvements.

**Relevance:** 9
**Novelty:** 8

---

## 3. [Neural Thermodynamic Laws for Large Language Model Training](https://arxiv.org/abs/2505.10559) <a id="link3"></a>

**ArXiv ID:** 2505.10559

**Authors:** Ziming Liu, Yizhou Liu, Jeff Gore, Max Tegmark

**Abstract:** Beyond neural scaling laws, little is known about the laws underlying large language models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new framework that offers fresh insights into LLM training dynamics. On the theoretical side, we demonstrate that key thermodynamic quantities (e.g., temperature, entropy, heat capacity, thermal conduction) and classical thermodynamic principles (e.g., the three laws of thermodynamics and the equipartition theorem) naturally emerge under river-valley loss landscape assumptions. On the practical side, this scientific perspective yields intuitive guidelines for designing learning rate schedules.

**Comment:** The paper introduces Neural Thermodynamic Laws, offering theoretical insights into LLM training dynamics, which aligns with the interest in foundational research on LLMs.

**Relevance:** 9
**Novelty:** 8

---

## 4. [Superposition Yields Robust Neural Scaling](https://arxiv.org/abs/2505.10465) <a id="link4"></a>

**ArXiv ID:** 2505.10465

**Authors:** Yizhou Liu, Ziming Liu, Jeff Gore

**Abstract:** The success of today's large language models (LLMs) depends on the observation that larger models perform better. However, the origin of this neural scaling law -- the finding that loss decreases as a power law with model size -- remains unclear. Starting from two empirical principles -- that LLMs represent more things than the model dimensions (widths) they have (i.e., representations are superposed), and that words or concepts in language occur with varying frequencies -- we constructed a toy model to study the loss scaling with model size. We found that when superposition is weak, meaning only the most frequent features are represented without interference, the scaling of loss with model size depends on the underlying feature frequency; if feature frequencies follow a power law, so does the loss. In contrast, under strong superposition, where all features are represented but overlap with each other, the loss becomes inversely proportional to the model dimension across a wide range of feature frequency distributions. This robust scaling behavior is explained geometrically: when many more vectors are packed into a lower dimensional space, the interference (squared overlaps) between vectors scales inversely with that dimension. We then analyzed four families of open-sourced LLMs and found that they exhibit strong superposition and quantitatively match the predictions of our toy model. The Chinchilla scaling law turned out to also agree with our results. We conclude that representation superposition is an important mechanism underlying the observed neural scaling laws. We anticipate that these insights will inspire new training strategies and model architectures to achieve better performance with less computation and fewer parameters.

**Comment:** The paper provides insights into neural scaling laws and representation superposition, which is relevant to representation learning and foundational research in LLMs.

**Relevance:** 9
**Novelty:** 8

---

## 5. [Learning Repetition-Invariant Representations for Polymer Informatics](https://arxiv.org/abs/2505.10726) <a id="link5"></a>

**ArXiv ID:** 2505.10726

**Authors:** Yihan Zhu, Gang Liu, Eric Inae, Tengfei Luo, Meng Jiang

**Abstract:** Polymers are large macromolecules composed of repeating structural units known as monomers and are widely applied in fields such as energy storage, construction, medicine, and aerospace. However, existing graph neural network methods, though effective for small molecules, only model the single unit of polymers and fail to produce consistent vector representations for the true polymer structure with varying numbers of units. To address this challenge, we introduce Graph Repetition Invariance (GRIN), a novel method to learn polymer representations that are invariant to the number of repeating units in their graph representations. GRIN integrates a graph-based maximum spanning tree alignment with repeat-unit augmentation to ensure structural consistency. We provide theoretical guarantees for repetition-invariance from both model and data perspectives, demonstrating that three repeating units are the minimal augmentation required for optimal invariant representation learning. GRIN outperforms state-of-the-art baselines on both homopolymer and copolymer benchmarks, learning stable, repetition-invariant representations that generalize effectively to polymer chains of unseen sizes.

**Comment:** The paper introduces a novel method for learning repetition-invariant representations in polymer informatics, which aligns with representation learning by providing insights into encoding information in deep networks.

**Relevance:** 9
**Novelty:** 8

---

## 6. [FlowVAT: Normalizing Flow Variational Inference with Affine-Invariant Tempering](https://arxiv.org/abs/2505.10466) <a id="link6"></a>

**ArXiv ID:** 2505.10466

**Authors:** Juehang Qin, Shixiao Liang, Christopher Tunnell

**Abstract:** Multi-modal and high-dimensional posteriors present significant challenges for variational inference, causing mode-seeking behavior and collapse despite the theoretical expressiveness of normalizing flows. Traditional annealing methods require temperature schedules and hyperparameter tuning, falling short of the goal of truly black-box variational inference. We introduce FlowVAT, a conditional tempering approach for normalizing flow variational inference that addresses these limitations. Our method tempers both the base and target distributions simultaneously, maintaining affine-invariance under tempering. By conditioning the normalizing flow on temperature, we leverage overparameterized neural networks' generalization capabilities to train a single flow representing the posterior across a range of temperatures. This preserves modes identified at higher temperatures when sampling from the variational posterior at $T = 1$, mitigating standard variational methods' mode-seeking behavior. In experiments with 2, 10, and 20 dimensional multi-modal distributions, FlowVAT outperforms traditional and adaptive annealing methods, finding more modes and achieving better ELBO values, particularly in higher dimensions where existing approaches fail. Our method requires minimal hyperparameter tuning and does not require an annealing schedule, advancing toward fully-automatic black-box variational inference for complicated posteriors.

**Comment:** The paper introduces FlowVAT, a novel method for variational inference using normalizing flows, which aligns with representation learning by addressing mode-seeking behavior and improving ELBO values.

**Relevance:** 8
**Novelty:** 7

---

## 7. [Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates](https://arxiv.org/abs/2505.10039) <a id="link7"></a>

**ArXiv ID:** 2505.10039

**Authors:** Hang Chen, Jiaying Zhu, Xinyu Yang, Wenya Wang

**Abstract:** Circuit discovery has gradually become one of the prominent methods for mechanistic interpretability, and research on circuit completeness has also garnered increasing attention. Methods of circuit discovery that do not guarantee completeness not only result in circuits that are not fixed across different runs but also cause key mechanisms to be omitted. The nature of incompleteness arises from the presence of OR gates within the circuit, which are often only partially detected in standard circuit discovery methods. To this end, we systematically introduce three types of logic gates: AND, OR, and ADDER gates, and decompose the circuit into combinations of these logical gates. Through the concept of these gates, we derive the minimum requirements necessary to achieve faithfulness and completeness. Furthermore, we propose a framework that combines noising-based and denoising-based interventions, which can be easily integrated into existing circuit discovery methods without significantly increasing computational complexity. This framework is capable of fully identifying the logic gates and distinguishing them within the circuit. In addition to the extensive experimental validation of the framework's ability to restore the faithfulness, completeness, and sparsity of circuits, using this framework, we uncover fundamental properties of the three logic gates, such as their proportions and contributions to the output, and explore how they behave among the functionalities of language models.

**Comment:** The paper discusses circuit discovery in language models, focusing on mechanistic interpretability and logic gates, which aligns with large language models and representation learning.

**Relevance:** 8
**Novelty:** 7

---

## 8. [The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think](https://arxiv.org/abs/2505.10185) <a id="link8"></a>

**ArXiv ID:** 2505.10185

**Authors:** Seongyun Lee, Seungone Kim, Minju Seo, Yongrae Jo, Dongyoung Go, Hyeonbin Hwang, Jinho Park, Xiang Yue, Sean Welleck, Graham Neubig, Moontae Lee, Minjoon Seo

**Abstract:** Long chain-of-thought (CoT) is an essential ingredient in effective usage of modern large language models, but our understanding of the reasoning strategies underlying these capabilities remains limited. While some prior works have attempted to categorize CoTs using predefined strategy types, such approaches are constrained by human intuition and fail to capture the full diversity of model behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up framework for analyzing and steering model reasoning. Our method automatically extracts diverse reasoning criteria from model-generated CoTs, embeds them into a semantic space, clusters them into representative categories, and derives contrastive rubrics to interpret reasoning behavior. Human evaluations show that this framework produces more interpretable and comprehensive analyses than existing methods. Moreover, we demonstrate that this understanding enables performance gains: we can predict which strategy a model is likely to use and guide it toward more effective alternatives. Finally, we provide practical insights, such as that training data format (e.g., free-form vs. multiple-choice) has a far greater impact on reasoning behavior than data domain, underscoring the importance of format-aware model design.

**Comment:** The paper introduces a framework for analyzing and steering model reasoning, which aligns with the interest in theoretical insights into LLM behavior and interpretability.

**Relevance:** 8
**Novelty:** 7

---

## 9. [ZEUS: Zero-shot Embeddings for Unsupervised Separation of Tabular Data](https://arxiv.org/abs/2505.10704) <a id="link9"></a>

**ArXiv ID:** 2505.10704

**Authors:** Patryk Marszałek, Tomasz Kuśmierczyk, Witold Wydmański, Jacek Tabor, Marek Śmieja

**Abstract:** Clustering tabular data remains a significant open challenge in data analysis and machine learning. Unlike for image data, similarity between tabular records often varies across datasets, making the definition of clusters highly dataset-dependent. Furthermore, the absence of supervised signals complicates hyperparameter tuning in deep learning clustering methods, frequently resulting in unstable performance. To address these issues and reduce the need for per-dataset tuning, we adopt an emerging approach in deep learning: zero-shot learning. We propose ZEUS, a self-contained model capable of clustering new datasets without any additional training or fine-tuning. It operates by decomposing complex datasets into meaningful components that can then be clustered effectively. Thanks to pre-training on synthetic datasets generated from a latent-variable prior, it generalizes across various datasets without requiring user intervention. To the best of our knowledge, ZEUS is the first zero-shot method capable of generating embeddings for tabular data in a fully unsupervised manner. Experimental results demonstrate that it performs on par with or better than traditional clustering algorithms and recent deep learning-based methods, while being significantly faster and more user-friendly.

**Comment:** ZEUS introduces a zero-shot method for clustering tabular data, focusing on representation learning with a novel approach to unsupervised learning.

**Relevance:** 8
**Novelty:** 7

---

## 10. [SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\mathcal{O}(T)$ Complexity](https://arxiv.org/abs/2505.10352) <a id="link10"></a>

**ArXiv ID:** 2505.10352

**Authors:** Shihao Zou, Qingfeng Li, Wei Ji, Jingjing Li, Yongkui Yang, Guoqi Li, Chao Dong

**Abstract:** Spiking Neural Networks (SNNs) have shown competitive performance to Artificial Neural Networks (ANNs) in various vision tasks, while offering superior energy efficiency. However, existing SNN-based Transformers primarily focus on single-image tasks, emphasizing spatial features while not effectively leveraging SNNs' efficiency in video-based vision tasks. In this paper, we introduce SpikeVideoFormer, an efficient spike-driven video Transformer, featuring linear temporal complexity $\mathcal{O}(T)$. Specifically, we design a spike-driven Hamming attention (SDHA) which provides a theoretically guided adaptation from traditional real-valued attention to spike-driven attention. Building on SDHA, we further analyze various spike-driven space-time attention designs and identify an optimal scheme that delivers appealing performance for video tasks, while maintaining only linear temporal complexity. The generalization ability and efficiency of our model are demonstrated across diverse downstream video tasks, including classification, human pose tracking, and semantic segmentation. Empirical results show our method achieves state-of-the-art (SOTA) performance compared to existing SNN approaches, with over 15\% improvement on the latter two tasks. Additionally, it matches the performance of recent ANN-based methods while offering significant efficiency gains, achieving $\times 16$, $\times 10$ and $\times 5$ improvements on the three tasks. https://github.com/JimmyZou/SpikeVideoFormer

**Comment:** The paper introduces a spike-driven video Transformer, which is relevant to model architecture innovations.

**Relevance:** 8
**Novelty:** 7

---

## 11. [Emergence of Structure in Ensembles of Random Neural Networks](https://arxiv.org/abs/2505.10331) <a id="link11"></a>

**ArXiv ID:** 2505.10331

**Authors:** Luca Muscarnera, Luigi Loreti, Giovanni Todeschini, Alessio Fumagalli, Francesco Regazzoni

**Abstract:** Randomness is ubiquitous in many applications across data science and machine learning. Remarkably, systems composed of random components often display emergent global behaviors that appear deterministic, manifesting a transition from microscopic disorder to macroscopic organization. In this work, we introduce a theoretical model for studying the emergence of collective behaviors in ensembles of random classifiers. We argue that, if the ensemble is weighted through the Gibbs measure defined by adopting the classification loss as an energy, then there exists a finite temperature parameter for the distribution such that the classification is optimal, with respect to the loss (or the energy). Interestingly, for the case in which samples are generated by a Gaussian distribution and labels are constructed by employing a teacher perceptron, we analytically prove and numerically confirm that such optimal temperature does not depend neither on the teacher classifier (which is, by construction of the learning problem, unknown), nor on the number of random classifiers, highlighting the universal nature of the observed behavior. Experiments on the MNIST dataset underline the relevance of this phenomenon in high-quality, noiseless, datasets. Finally, a physical analogy allows us to shed light on the self-organizing nature of the studied phenomenon.

**Comment:** The paper presents a theoretical model for the emergence of structure in ensembles of random neural networks, which is relevant to understanding training dynamics and representation learning in neural networks.

**Relevance:** 8
**Novelty:** 7

---

# Paper Selection Prompt

You are a helpful paper reading assistant whose job is to read daily posts from ArXiv and identify a few papers that your friend will enjoy reading.
Your job is to carefully read the paper titles and abstracts below and find the ones that match the criteria below.

## Instructions

Write the response in JSONL format with {ARXIVID, COMMENT, RELEVANCE, NOVELTY} on each line, one for each paper.

- ARXIVID: should be the ArXiv ID.
- COMMENT: should identify whether there is a criteria that match the paper very closely. These matches should not be based on general terms like "language modeling" or "advancements" and should specifically refer to a criterion. No need to mention the non-matching criteria.
- RELEVANCE: should be a score from 1-10.
- NOVELTY: should be a score from 1-10.

## Scoring Criteria

> The "Relevance" score measures how closely the paper aligns with the core topics of the prompt.
> The "Novelty" score assesses the originality and impact of the paper.
> They are two **ORTHONORMAL** axes and **SHOULD NOT** be confused with each other.

### Relevance Scoring

- Relevance 9-10 (Completely Relevant)
  - Focus: Fully aligned with core topics with no deviation, score the highest if contains relevant keywords in it.
  - Examples: Papers focused on foundational methods or theoretical research, whose titles contain topic keywords like "MoE".

- Relevance 7-8 (Relevant)
  - Focus: Retain a solid link to the main research area, though may touch on peripheral elements.
  - Examples: Papers research on the fundamental part of MoE through a less critical aspect like its behavior in GNN.

- Relevance 5-6 (Borderline)
  - Focus: Maintains a link to the core topic but also extends into at least one other domain/area beyond the primary focus.
  - Examples: Work referencing MoE centered on reinforcement learning.

- Relevance 3-4 (Irrelevant)
  - Focus: Largely outside our interests with no association to our topics.
  - Examples: Application-focused papers like using MoE to solve a problem in the real world.

- Relevance 1-2 (Ignore)
  - Focus: Purely unrelated to our topics. Completely a different domain.
  - **Exception**: If the paper hints at a cutting-edge, radically new direction that could eventually transform the primary domain, consider a score of 9–10 despite initial appearances. (Usually a very rare concept that belongs to the fundamental research)

### Novelty Scoring

- Novelty 9-10 (Breakthrough)
  - Definition: Groundbreaking methods/theory introducing new directions or solving major challenges.
  - Examples: Entirely new paradigm for foundational models; a novel theory transforming representation learning.

- Novelty 7-8 (Improvements)
  - Definition: Substantial insights/enhancements, though not a full paradigm shift.
  - Examples: Modifications on existing methods yielding significantly better results.

- Novelty 5-6 (Borderline)
  - Definition: Incremental contributions with possible long-term benefits, not immediately transformative.
  - Examples: Moderately novel extension to an existing architecture; refining current methods without fundamentally altering them.

- Novelty 3-4 (Tangential)
  - Definition: Minor or domain-specific improvements with limited broader impact.
  - Examples: Slight modifications to known methods with strange motivation; purely engineering jobs like a new benchmark/dataset.

- Novelty 1-2 (Low)
  - Definition: Minimal originality, applying standard approaches without real innovation.
  - Examples: Using an off-the-shelf model without adding new insights; purely application-driven studies like finetuning a pretrained model using existing methods.

## Papers

[PAPER LIST HERE]

## Relevant Topics

Use the following relevance criteria to focus on foundational research. Keep **relevant** papers and filter out **irrelevant** ones. Avoid purely **application-driven** work.

1. Representation Learning
   - Relevant: Insights into how deep networks encode information, feature/dictionary learning, sparse/contrastive methods, training dynamics in neural networks.
   - Irrelevant: Standard applications of known techniques lacking new theoretical or methodological contributions.

2. Model Architecture
   - Relevant: Mixture-of-Experts (MoE), Transformers, Conditional/Dynamic Networks, Autoencoders, analysis on existing architectures (like encoder-decoder), or other architectural innovations.
   - Irrelevant: Merely using existing architectures for a certain task without insights into the structure themselves.

3. Model Compression
   - Relevant: Sparsity, pruning, quantization, low-rank approaches, KV cache, or other algorithmic/theoretical efficiency breakthroughs.
   - Irrelevant: Straightforward applications of existing compression methods to new tasks.

4. Large Language Models (LLMs)
   - Relevant: Major breakthroughs in pretraining or architecture, theoretical insights into LLM behavior/interpretability.
   - Irrelevant: Domain-specific usage (e.g., translation, jail-breaking), finetuning or inference tricks (e.g., instruction tuning, chain-of-thoughts, data mixing), or empirical dataset/benchmark studies and text-level analysis (e.g. hallucination, reasoning, safety).

5. AI for Science
   - Relevant: Foundational research in molecular/protein modeling, new generative paradigms, or significant architecture-level innovations.
   - Irrelevant: Conventional, domain-specific applications without new theoretical perspectives.

6. Emerging Trends
   - Relevant: Cutting-edge theoretical work challenging established assumptions or introducing broad new paradigms.
   - Irrelevant: Incremental improvements or trend-following without novel insights.

**Keywords:**

- Relevant: Mixture of Experts (MoE), Representation Learning, Compression/Efficiency, Sparse/Sparsity, Pruning, Quantization, Low-rank, Foundation Model, etc.
- Irrelevant: Reinforcement Learning, Transfer Learning, Federated Learning, Online Learning, Diffusion Models, etc.
- Application: Image Segmentation, Medical Imaging, 3D Vision, Video Understanding, Information Retrieval, Summarization, Recommendation Systems, Machine Translation, Speech Recognition, Signal Processing, Spatial/Temporal Modeling, Time Series, Knowledge Graph, etc.