{
    "2505.10689": {
        "SCORE": 17,
        "ARXIVID": "2505.10689",
        "COMMENT": "The paper proposes a probabilistic framework for dynamic quantization, which is relevant to model compression by introducing an input-adaptive rescaling method.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Gabriele Santini",
            "Francesco Paissan",
            "Elisabetta Farella"
        ],
        "title": "A probabilistic framework for dynamic quantization",
        "abstract": "We propose a probabilistic framework for dynamic quantization of neural networks that allows for a computationally efficient input-adaptive rescaling of the quantization parameters. Our framework applies a probabilistic model to the network's pre-activations through a lightweight surrogate, enabling the adaptive adjustment of the quantization parameters on a per-input basis without significant memory overhead. We validate our approach on a set of popular computer vision tasks and models, observing only a negligible loss in performance. Our method strikes the best performance and computational overhead tradeoff compared to standard quantization strategies.",
        "arxiv_id": "2505.10689"
    },
    "2505.10475": {
        "SCORE": 17,
        "ARXIVID": "2505.10475",
        "COMMENT": "The paper introduces a new scaling paradigm for language models, which aligns with the interest in model architecture and efficiency improvements.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Mouxiang Chen",
            "Binyuan Hui",
            "Zeyu Cui",
            "Jiaxi Yang",
            "Dayiheng Liu",
            "Jianling Sun",
            "Junyang Lin",
            "Zhongxin Liu"
        ],
        "title": "Parallel Scaling Law for Language Models",
        "abstract": "It is commonly believed that scaling language models should commit a significant space or time cost, by increasing the parameters (parameter scaling) or output tokens (inference-time scaling). We introduce the third and more inference-efficient scaling paradigm: increasing the model's parallel computation during both training and inference time. We apply $P$ diverse and learnable transformations to the input, execute forward passes of the model in parallel, and dynamically aggregate the $P$ outputs. This method, namely parallel scaling (ParScale), scales parallel computation by reusing existing parameters and can be applied to any model structure, optimization procedure, data, or task. We theoretically propose a new scaling law and validate it through large-scale pre-training, which shows that a model with $P$ parallel streams is similar to scaling the parameters by $O(\\log P)$ while showing superior inference efficiency. For example, ParScale can use up to 22$\\times$ less memory increase and 6$\\times$ less latency increase compared to parameter scaling that achieves the same performance improvement. It can also recycle an off-the-shelf pre-trained model into a parallelly scaled one by post-training on a small amount of tokens, further reducing the training budget. The new scaling law we discovered potentially facilitates the deployment of more powerful models in low-resource scenarios, and provides an alternative perspective for the role of computation in machine learning.",
        "arxiv_id": "2505.10475"
    },
    "2505.10559": {
        "SCORE": 17,
        "ARXIVID": "2505.10559",
        "COMMENT": "The paper introduces Neural Thermodynamic Laws, offering theoretical insights into LLM training dynamics, which aligns with the interest in foundational research on LLMs.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Ziming Liu",
            "Yizhou Liu",
            "Jeff Gore",
            "Max Tegmark"
        ],
        "title": "Neural Thermodynamic Laws for Large Language Model Training",
        "abstract": "Beyond neural scaling laws, little is known about the laws underlying large language models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new framework that offers fresh insights into LLM training dynamics. On the theoretical side, we demonstrate that key thermodynamic quantities (e.g., temperature, entropy, heat capacity, thermal conduction) and classical thermodynamic principles (e.g., the three laws of thermodynamics and the equipartition theorem) naturally emerge under river-valley loss landscape assumptions. On the practical side, this scientific perspective yields intuitive guidelines for designing learning rate schedules.",
        "arxiv_id": "2505.10559"
    },
    "2505.10465": {
        "SCORE": 17,
        "ARXIVID": "2505.10465",
        "COMMENT": "The paper provides insights into neural scaling laws and representation superposition, which is relevant to representation learning and foundational research in LLMs.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Yizhou Liu",
            "Ziming Liu",
            "Jeff Gore"
        ],
        "title": "Superposition Yields Robust Neural Scaling",
        "abstract": "The success of today's large language models (LLMs) depends on the observation that larger models perform better. However, the origin of this neural scaling law -- the finding that loss decreases as a power law with model size -- remains unclear. Starting from two empirical principles -- that LLMs represent more things than the model dimensions (widths) they have (i.e., representations are superposed), and that words or concepts in language occur with varying frequencies -- we constructed a toy model to study the loss scaling with model size. We found that when superposition is weak, meaning only the most frequent features are represented without interference, the scaling of loss with model size depends on the underlying feature frequency; if feature frequencies follow a power law, so does the loss. In contrast, under strong superposition, where all features are represented but overlap with each other, the loss becomes inversely proportional to the model dimension across a wide range of feature frequency distributions. This robust scaling behavior is explained geometrically: when many more vectors are packed into a lower dimensional space, the interference (squared overlaps) between vectors scales inversely with that dimension. We then analyzed four families of open-sourced LLMs and found that they exhibit strong superposition and quantitatively match the predictions of our toy model. The Chinchilla scaling law turned out to also agree with our results. We conclude that representation superposition is an important mechanism underlying the observed neural scaling laws. We anticipate that these insights will inspire new training strategies and model architectures to achieve better performance with less computation and fewer parameters.",
        "arxiv_id": "2505.10465"
    },
    "2505.10726": {
        "SCORE": 17,
        "ARXIVID": "2505.10726",
        "COMMENT": "The paper introduces a novel method for learning repetition-invariant representations in polymer informatics, which aligns with representation learning by providing insights into encoding information in deep networks.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Yihan Zhu",
            "Gang Liu",
            "Eric Inae",
            "Tengfei Luo",
            "Meng Jiang"
        ],
        "title": "Learning Repetition-Invariant Representations for Polymer Informatics",
        "abstract": "Polymers are large macromolecules composed of repeating structural units known as monomers and are widely applied in fields such as energy storage, construction, medicine, and aerospace. However, existing graph neural network methods, though effective for small molecules, only model the single unit of polymers and fail to produce consistent vector representations for the true polymer structure with varying numbers of units. To address this challenge, we introduce Graph Repetition Invariance (GRIN), a novel method to learn polymer representations that are invariant to the number of repeating units in their graph representations. GRIN integrates a graph-based maximum spanning tree alignment with repeat-unit augmentation to ensure structural consistency. We provide theoretical guarantees for repetition-invariance from both model and data perspectives, demonstrating that three repeating units are the minimal augmentation required for optimal invariant representation learning. GRIN outperforms state-of-the-art baselines on both homopolymer and copolymer benchmarks, learning stable, repetition-invariant representations that generalize effectively to polymer chains of unseen sizes.",
        "arxiv_id": "2505.10726"
    },
    "2505.10466": {
        "SCORE": 15,
        "ARXIVID": "2505.10466",
        "COMMENT": "The paper introduces FlowVAT, a novel method for variational inference using normalizing flows, which aligns with representation learning by addressing mode-seeking behavior and improving ELBO values.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Juehang Qin",
            "Shixiao Liang",
            "Christopher Tunnell"
        ],
        "title": "FlowVAT: Normalizing Flow Variational Inference with Affine-Invariant Tempering",
        "abstract": "Multi-modal and high-dimensional posteriors present significant challenges for variational inference, causing mode-seeking behavior and collapse despite the theoretical expressiveness of normalizing flows. Traditional annealing methods require temperature schedules and hyperparameter tuning, falling short of the goal of truly black-box variational inference. We introduce FlowVAT, a conditional tempering approach for normalizing flow variational inference that addresses these limitations. Our method tempers both the base and target distributions simultaneously, maintaining affine-invariance under tempering. By conditioning the normalizing flow on temperature, we leverage overparameterized neural networks' generalization capabilities to train a single flow representing the posterior across a range of temperatures. This preserves modes identified at higher temperatures when sampling from the variational posterior at $T = 1$, mitigating standard variational methods' mode-seeking behavior. In experiments with 2, 10, and 20 dimensional multi-modal distributions, FlowVAT outperforms traditional and adaptive annealing methods, finding more modes and achieving better ELBO values, particularly in higher dimensions where existing approaches fail. Our method requires minimal hyperparameter tuning and does not require an annealing schedule, advancing toward fully-automatic black-box variational inference for complicated posteriors.",
        "arxiv_id": "2505.10466"
    },
    "2505.10039": {
        "SCORE": 15,
        "ARXIVID": "2505.10039",
        "COMMENT": "The paper discusses circuit discovery in language models, focusing on mechanistic interpretability and logic gates, which aligns with large language models and representation learning.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Hang Chen",
            "Jiaying Zhu",
            "Xinyu Yang",
            "Wenya Wang"
        ],
        "title": "Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates",
        "abstract": "Circuit discovery has gradually become one of the prominent methods for mechanistic interpretability, and research on circuit completeness has also garnered increasing attention. Methods of circuit discovery that do not guarantee completeness not only result in circuits that are not fixed across different runs but also cause key mechanisms to be omitted. The nature of incompleteness arises from the presence of OR gates within the circuit, which are often only partially detected in standard circuit discovery methods. To this end, we systematically introduce three types of logic gates: AND, OR, and ADDER gates, and decompose the circuit into combinations of these logical gates. Through the concept of these gates, we derive the minimum requirements necessary to achieve faithfulness and completeness. Furthermore, we propose a framework that combines noising-based and denoising-based interventions, which can be easily integrated into existing circuit discovery methods without significantly increasing computational complexity. This framework is capable of fully identifying the logic gates and distinguishing them within the circuit. In addition to the extensive experimental validation of the framework's ability to restore the faithfulness, completeness, and sparsity of circuits, using this framework, we uncover fundamental properties of the three logic gates, such as their proportions and contributions to the output, and explore how they behave among the functionalities of language models.",
        "arxiv_id": "2505.10039"
    },
    "2505.10185": {
        "SCORE": 15,
        "ARXIVID": "2505.10185",
        "COMMENT": "The paper introduces a framework for analyzing and steering model reasoning, which aligns with the interest in theoretical insights into LLM behavior and interpretability.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Seongyun Lee",
            "Seungone Kim",
            "Minju Seo",
            "Yongrae Jo",
            "Dongyoung Go",
            "Hyeonbin Hwang",
            "Jinho Park",
            "Xiang Yue",
            "Sean Welleck",
            "Graham Neubig",
            "Moontae Lee",
            "Minjoon Seo"
        ],
        "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think",
        "abstract": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of modern large language models, but our understanding of the reasoning strategies underlying these capabilities remains limited. While some prior works have attempted to categorize CoTs using predefined strategy types, such approaches are constrained by human intuition and fail to capture the full diversity of model behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up framework for analyzing and steering model reasoning. Our method automatically extracts diverse reasoning criteria from model-generated CoTs, embeds them into a semantic space, clusters them into representative categories, and derives contrastive rubrics to interpret reasoning behavior. Human evaluations show that this framework produces more interpretable and comprehensive analyses than existing methods. Moreover, we demonstrate that this understanding enables performance gains: we can predict which strategy a model is likely to use and guide it toward more effective alternatives. Finally, we provide practical insights, such as that training data format (e.g., free-form vs. multiple-choice) has a far greater impact on reasoning behavior than data domain, underscoring the importance of format-aware model design.",
        "arxiv_id": "2505.10185"
    },
    "2505.10704": {
        "SCORE": 15,
        "ARXIVID": "2505.10704",
        "COMMENT": "ZEUS introduces a zero-shot method for clustering tabular data, focusing on representation learning with a novel approach to unsupervised learning.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Patryk Marsza\u0142ek",
            "Tomasz Ku\u015bmierczyk",
            "Witold Wydma\u0144ski",
            "Jacek Tabor",
            "Marek \u015amieja"
        ],
        "title": "ZEUS: Zero-shot Embeddings for Unsupervised Separation of Tabular Data",
        "abstract": "Clustering tabular data remains a significant open challenge in data analysis and machine learning. Unlike for image data, similarity between tabular records often varies across datasets, making the definition of clusters highly dataset-dependent. Furthermore, the absence of supervised signals complicates hyperparameter tuning in deep learning clustering methods, frequently resulting in unstable performance. To address these issues and reduce the need for per-dataset tuning, we adopt an emerging approach in deep learning: zero-shot learning. We propose ZEUS, a self-contained model capable of clustering new datasets without any additional training or fine-tuning. It operates by decomposing complex datasets into meaningful components that can then be clustered effectively. Thanks to pre-training on synthetic datasets generated from a latent-variable prior, it generalizes across various datasets without requiring user intervention. To the best of our knowledge, ZEUS is the first zero-shot method capable of generating embeddings for tabular data in a fully unsupervised manner. Experimental results demonstrate that it performs on par with or better than traditional clustering algorithms and recent deep learning-based methods, while being significantly faster and more user-friendly.",
        "arxiv_id": "2505.10704"
    },
    "2505.10352": {
        "SCORE": 15,
        "ARXIVID": "2505.10352",
        "COMMENT": "The paper introduces a spike-driven video Transformer, which is relevant to model architecture innovations.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Shihao Zou",
            "Qingfeng Li",
            "Wei Ji",
            "Jingjing Li",
            "Yongkui Yang",
            "Guoqi Li",
            "Chao Dong"
        ],
        "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity",
        "abstract": "Spiking Neural Networks (SNNs) have shown competitive performance to Artificial Neural Networks (ANNs) in various vision tasks, while offering superior energy efficiency. However, existing SNN-based Transformers primarily focus on single-image tasks, emphasizing spatial features while not effectively leveraging SNNs' efficiency in video-based vision tasks. In this paper, we introduce SpikeVideoFormer, an efficient spike-driven video Transformer, featuring linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design a spike-driven Hamming attention (SDHA) which provides a theoretically guided adaptation from traditional real-valued attention to spike-driven attention. Building on SDHA, we further analyze various spike-driven space-time attention designs and identify an optimal scheme that delivers appealing performance for video tasks, while maintaining only linear temporal complexity. The generalization ability and efficiency of our model are demonstrated across diverse downstream video tasks, including classification, human pose tracking, and semantic segmentation. Empirical results show our method achieves state-of-the-art (SOTA) performance compared to existing SNN approaches, with over 15\\% improvement on the latter two tasks. Additionally, it matches the performance of recent ANN-based methods while offering significant efficiency gains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the three tasks. https://github.com/JimmyZou/SpikeVideoFormer",
        "arxiv_id": "2505.10352"
    },
    "2505.10331": {
        "SCORE": 15,
        "ARXIVID": "2505.10331",
        "COMMENT": "The paper presents a theoretical model for the emergence of structure in ensembles of random neural networks, which is relevant to understanding training dynamics and representation learning in neural networks.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Luca Muscarnera",
            "Luigi Loreti",
            "Giovanni Todeschini",
            "Alessio Fumagalli",
            "Francesco Regazzoni"
        ],
        "title": "Emergence of Structure in Ensembles of Random Neural Networks",
        "abstract": "Randomness is ubiquitous in many applications across data science and machine learning. Remarkably, systems composed of random components often display emergent global behaviors that appear deterministic, manifesting a transition from microscopic disorder to macroscopic organization. In this work, we introduce a theoretical model for studying the emergence of collective behaviors in ensembles of random classifiers. We argue that, if the ensemble is weighted through the Gibbs measure defined by adopting the classification loss as an energy, then there exists a finite temperature parameter for the distribution such that the classification is optimal, with respect to the loss (or the energy). Interestingly, for the case in which samples are generated by a Gaussian distribution and labels are constructed by employing a teacher perceptron, we analytically prove and numerically confirm that such optimal temperature does not depend neither on the teacher classifier (which is, by construction of the learning problem, unknown), nor on the number of random classifiers, highlighting the universal nature of the observed behavior. Experiments on the MNIST dataset underline the relevance of this phenomenon in high-quality, noiseless, datasets. Finally, a physical analogy allows us to shed light on the self-organizing nature of the studied phenomenon.",
        "arxiv_id": "2505.10331"
    }
}