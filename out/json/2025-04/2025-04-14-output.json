{
    "2504.08489": {
        "SCORE": 17,
        "ARXIVID": "2504.08489",
        "COMMENT": "The paper proposes a theoretically grounded deep learning algorithm with a focus on optimization, generalization, and approximation, aligning with foundational research in representation learning.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Michael Kohler",
            "Adam Krzyzak"
        ],
        "title": "Statistically guided deep learning",
        "abstract": "We present a theoretically well-founded deep learning algorithm for nonparametric regression. It uses over-parametrized deep neural networks with logistic activation function, which are fitted to the given data via gradient descent. We propose a special topology of these networks, a special random initialization of the weights, and a data-dependent choice of the learning rate and the number of gradient descent steps. We prove a theoretical bound on the expected $L_2$ error of this estimate, and illustrate its finite sample size performance by applying it to simulated data. Our results show that a theoretical analysis of deep learning which takes into account simultaneously optimization, generalization and approximation can result in a new deep learning estimate which has an improved finite sample performance.",
        "arxiv_id": "2504.08489"
    },
    "2504.08378": {
        "SCORE": 17,
        "ARXIVID": "2504.08378",
        "COMMENT": "The paper introduces ActiveFlow, a framework for scaling LLMs on mobile devices via active-weight swapping. It aligns with Model Compression and efficiency breakthroughs, particularly in DRAM-flash memory management.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Fucheng Jia",
            "Zewen Wu",
            "Shiqi Jiang",
            "Huiqiang Jiang",
            "Qianxi Zhang",
            "Yuqing Yang",
            "Yunxin Liu",
            "Ju Ren",
            "Deyu Zhang",
            "Ting Cao"
        ],
        "title": "Scaling Up On-Device LLMs via Active-Weight Swapping Between DRAM and Flash",
        "abstract": "Large language models (LLMs) are increasingly being deployed on mobile devices, but the limited DRAM capacity constrains the deployable model size. This paper introduces ActiveFlow, the first LLM inference framework that can achieve adaptive DRAM usage for modern LLMs (not ReLU-based), enabling the scaling up of deployable model sizes. The framework is based on the novel concept of active weight DRAM-flash swapping and incorporates three novel techniques: (1) Cross-layer active weights preloading. It uses the activations from the current layer to predict the active weights of several subsequent layers, enabling computation and data loading to overlap, as well as facilitating large I/O transfers. (2) Sparsity-aware self-distillation. It adjusts the active weights to align with the dense-model output distribution, compensating for approximations introduced by contextual sparsity. (3) Active weight DRAM-flash swapping pipeline. It orchestrates the DRAM space allocation among the hot weight cache, preloaded active weights, and computation-involved weights based on available memory. Results show ActiveFlow achieves the performance-cost Pareto frontier compared to existing efficiency optimization methods.",
        "arxiv_id": "2504.08378"
    },
    "2504.08730": {
        "SCORE": 17,
        "ARXIVID": "2504.08730",
        "COMMENT": "The paper provides a theoretical analysis of dimension reduction methods for derivative-informed operator learning, which aligns with foundational research in representation learning and AI for Science. It offers insights into approximation errors in neural operators.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Dingcheng Luo",
            "Thomas O'Leary-Roseberry",
            "Peng Chen",
            "Omar Ghattas"
        ],
        "title": "Dimension reduction for derivative-informed operator learning: An analysis of approximation errors",
        "abstract": "We study the derivative-informed learning of nonlinear operators between infinite-dimensional separable Hilbert spaces by neural networks. Such operators can arise from the solution of partial differential equations (PDEs), and are used in many simulation-based outer-loop tasks in science and engineering, such as PDE-constrained optimization, Bayesian inverse problems, and optimal experimental design. In these settings, the neural network approximations can be used as surrogate models to accelerate the solution of the outer-loop tasks. However, since outer-loop tasks in infinite dimensions often require knowledge of the underlying geometry, the approximation accuracy of the operator's derivatives can also significantly impact the performance of the surrogate model. Motivated by this, we analyze the approximation errors of neural operators in Sobolev norms over infinite-dimensional Gaussian input measures. We focus on the reduced basis neural operator (RBNO), which uses linear encoders and decoders defined on dominant input/output subspaces spanned by reduced sets of orthonormal bases. To this end, we study two methods for generating the bases; principal component analysis (PCA) and derivative-informed subspaces (DIS), which use the dominant eigenvectors of the covariance of the data or the derivatives as the reduced bases, respectively. We then derive bounds for errors arising from both the dimension reduction and the latent neural network approximation, including the sampling errors associated with the empirical estimation of the PCA/DIS. Our analysis is validated on numerical experiments with elliptic PDEs, where our results show that bases informed by the map (i.e., DIS or output PCA) yield accurate reconstructions and generalization errors for both the operator and its derivatives, while input PCA may underperform unless ranks and training sample sizes are sufficiently large.",
        "arxiv_id": "2504.08730"
    },
    "2504.08300": {
        "SCORE": 17,
        "ARXIVID": "2504.08300",
        "COMMENT": "The paper explores rote memorization versus genuine capability learning in LLMs, which aligns with foundational insights into LLM behavior and interpretability.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Yuyang Xu",
            "Renjun Hu",
            "Haochao Ying",
            "Jian Wu",
            "Xing Shi",
            "Wei Lin"
        ],
        "title": "Large language models could be rote learners",
        "abstract": "Multiple-choice question (MCQ) benchmarks are widely used for evaluating Large Language Models (LLMs), yet their reliability is undermined by benchmark contamination. In this study, we reframe contamination as an inherent aspect of learning and seek to disentangle genuine capability acquisition from superficial memorization in LLM evaluation. First, by analyzing model performance under different memorization conditions, we uncover a counterintuitive trend: LLMs perform worse on memorized MCQs than on non-memorized ones, indicating the coexistence of two distinct learning phenomena, i.e., rote memorization and genuine capability learning. To disentangle them, we propose TrinEval, a novel evaluation framework that reformulates MCQs into an alternative trinity format, reducing memorization while preserving knowledge assessment. Experiments validate TrinEval's effectiveness in reformulation, and its evaluation reveals that common LLMs may memorize by rote 20.5% of knowledge points (in MMLU on average).",
        "arxiv_id": "2504.08300"
    },
    "2504.08192": {
        "SCORE": 17,
        "ARXIVID": "2504.08192",
        "COMMENT": "The paper introduces a dynamic sparse autoencoder method for precision unlearning in LLMs, which aligns with foundational research in model compression and sparsity.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Aashiq Muhamed",
            "Jacopo Bonato",
            "Mona Diab",
            "Virginia Smith"
        ],
        "title": "SAEs $\\textit{Can}$ Improve Unlearning: Dynamic Sparse Autoencoder Guardrails for Precision Unlearning in LLMs",
        "abstract": "Machine unlearning is a promising approach to improve LLM safety by removing unwanted knowledge from the model. However, prevailing gradient-based unlearning methods suffer from issues such as high computational costs, hyperparameter instability, poor sequential unlearning capability, vulnerability to relearning attacks, low data efficiency, and lack of interpretability. While Sparse Autoencoders are well-suited to improve these aspects by enabling targeted activation-based unlearning, prior approaches underperform gradient-based methods. This work demonstrates that, contrary to these earlier findings, SAEs can significantly improve unlearning when employed dynamically. We introduce $\\textbf{Dynamic DAE Guardrails}$ (DSG), a novel method for precision unlearning that leverages principled feature selection and a dynamic classifier. Our experiments show DSG substantially outperforms leading unlearning methods, achieving superior forget-utility trade-offs. DSG addresses key drawbacks of gradient-based approaches for unlearning -- offering enhanced computational efficiency and stability, robust performance in sequential unlearning, stronger resistance to relearning attacks, better data efficiency including zero-shot settings, and more interpretable unlearning.",
        "arxiv_id": "2504.08192"
    },
    "2504.08628": {
        "SCORE": 17,
        "ARXIVID": "2504.08628",
        "COMMENT": "The paper studies the intrinsic dimension of data learned by CNNs trained with gradient descent, providing theoretical insights into training dynamics and representation learning.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Chenyang Zhang",
            "Peifeng Gao",
            "Difan Zou",
            "Yuan Cao"
        ],
        "title": "Gradient Descent Robustly Learns the Intrinsic Dimension of Data in Training Convolutional Neural Networks",
        "abstract": "Modern neural networks are usually highly over-parameterized. Behind the wide usage of over-parameterized networks is the belief that, if the data are simple, then the trained network will be automatically equivalent to a simple predictor. Following this intuition, many existing works have studied different notions of \"ranks\" of neural networks and their relation to the rank of data. In this work, we study the rank of convolutional neural networks (CNNs) trained by gradient descent, with a specific focus on the robustness of the rank to image background noises. Specifically, we point out that, when adding background noises to images, the rank of the CNN trained with gradient descent is affected far less compared with the rank of the data. We support our claim with a theoretical case study, where we consider a particular data model to characterize low-rank clean images with added background noises. We prove that CNNs trained by gradient descent can learn the intrinsic dimension of clean images, despite the presence of relatively large background noises. We also conduct experiments on synthetic and real datasets to further validate our claim.",
        "arxiv_id": "2504.08628"
    },
    "2504.08729": {
        "SCORE": 17,
        "ARXIVID": "2504.08729",
        "COMMENT": "The paper explores sparse autoencoders (SAEs) to analyze and steer CLIP's vision transformer, aligning with representation learning and architectural analysis. It provides insights into sparsity patterns and steerability, which are foundational topics.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Sonia Joseph",
            "Praneet Suresh",
            "Ethan Goldfarb",
            "Lorenz Hufe",
            "Yossi Gandelsman",
            "Robert Graham",
            "Danilo Bzdok",
            "Wojciech Samek",
            "Blake Aaron Richards"
        ],
        "title": "Steering CLIP's vision transformer with sparse autoencoders",
        "abstract": "While vision models are highly capable, their internal mechanisms remain poorly understood -- a challenge which sparse autoencoders (SAEs) have helped address in language, but which remains underexplored in vision. We address this gap by training SAEs on CLIP's vision transformer and uncover key differences between vision and language processing, including distinct sparsity patterns for SAEs trained across layers and token types. We then provide the first systematic analysis on the steerability of CLIP's vision transformer by introducing metrics to quantify how precisely SAE features can be steered to affect the model's output. We find that 10-15\\% of neurons and features are steerable, with SAEs providing thousands more steerable features than the base model. Through targeted suppression of SAE features, we then demonstrate improved performance on three vision disentanglement tasks (CelebA, Waterbirds, and typographic attacks), finding optimal disentanglement in middle model layers, and achieving state-of-the-art performance on defense against typographic attacks.",
        "arxiv_id": "2504.08729"
    },
    "2504.08096": {
        "SCORE": 17,
        "ARXIVID": "2504.08096",
        "COMMENT": "This paper proposes a novel computational framework using Transformers to model cellular development based on the principle of least action. It aligns with 'AI for Science' as it introduces a foundational approach to understanding cellular processes through thermodynamic and informational metrics, which could have broad implications.",
        "RELEVANCE": 9,
        "NOVELTY": 8,
        "authors": [
            "Rohola Zandie",
            "Farhan Khodaee",
            "Yufan Xia",
            "Elazer R. Edelman"
        ],
        "title": "Cellular Development Follows the Path of Minimum Action",
        "abstract": "Cellular development follows a stochastic yet rule-governed trajectory, though the underlying principles remain elusive. Here, we propose that cellular development follows paths of least action, aligning with foundational physical laws that govern dynamic systems across nature. We introduce a computational framework that takes advantage of the deep connection between the principle of least action and maximum entropy to model developmental processes using Transformers architecture. This approach enables precise quantification of entropy production, information flow curvature, and local irreversibility for developmental asymmetry in single-cell RNA sequence data. Within this unified framework, we provide interpretable metrics: entropy to capture exploration-exploitation trade-offs, curvature to assess plasticity-elasticity dynamics, and entropy production to characterize dedifferentiation and transdifferentiation. We validate our method across both single-cell and embryonic development datasets, demonstrating its ability to reveal hidden thermodynamic and informational constraints shaping cellular fate decisions.",
        "arxiv_id": "2504.08096"
    },
    "2504.08335": {
        "SCORE": 16,
        "ARXIVID": "2504.08335",
        "COMMENT": "The paper provides theoretical bounds on neural network convergence to Gaussian distributions, which aligns with foundational research in understanding training dynamics and representation learning.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Lucia Celli",
            "Giovanni Peccati"
        ],
        "title": "Entropic bounds for conditionally Gaussian vectors and applications to neural networks",
        "abstract": "Using entropic inequalities from information theory, we provide new bounds on the total variation and 2-Wasserstein distances between a conditionally Gaussian law and a Gaussian law with invertible covariance matrix. We apply our results to quantify the speed of convergence to Gaussian of a randomly initialized fully connected neural network and its derivatives - evaluated in a finite number of inputs - when the initialization is Gaussian and the sizes of the inner layers diverge to infinity. Our results require mild assumptions on the activation function, and allow one to recover optimal rates of convergence in a variety of distances, thus improving and extending the findings of Basteri and Trevisan (2023), Favaro et al. (2023), Trevisan (2024) and Apollonio et al. (2024). One of our main tools are the quantitative cumulant estimates established in Hanin (2024). As an illustration, we apply our results to bound the total variation distance between the Bayesian posterior law of the neural network and its derivatives, and the posterior law of the corresponding Gaussian limit: this yields quantitative versions of a posterior CLT by Hron et al. (2022), and extends several estimates by Trevisan (2024) to the total variation metric.",
        "arxiv_id": "2504.08335"
    },
    "2504.08178": {
        "SCORE": 16,
        "ARXIVID": "2504.08178",
        "COMMENT": "The paper provides theoretical analysis of SGD with sub-quadratic tails, which contributes to foundational understanding of optimization dynamics in machine learning.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Yixuan Zhang (Lucy)",
            "Dongyan (Lucy)",
            "Huo",
            "Yudong Chen",
            "Qiaomin Xie"
        ],
        "title": "A Piecewise Lyapunov Analysis of sub--quadratic SGD: Applications to Robust and Quantile Regression",
        "abstract": "Motivated by robust and quantile regression problems, {we investigate the stochastic gradient descent (SGD) algorithm} for minimizing an objective function $f$ that is locally strongly convex with a sub--quadratic tail. This setting covers many widely used online statistical methods. We introduce a novel piecewise Lyapunov function that enables us to handle functions $f$ with only first-order differentiability, which includes a wide range of popular loss functions such as Huber loss. Leveraging our proposed Lyapunov function, we derive finite-time moment bounds under general diminishing stepsizes, as well as constant stepsizes. We further establish the weak convergence, central limit theorem and bias characterization under constant stepsize, providing the first geometrical convergence result for sub--quadratic SGD. Our results have wide applications, especially in online statistical methods. In particular, we discuss two applications of our results. 1) Online robust regression: We consider a corrupted linear model with sub--exponential covariates and heavy--tailed noise. Our analysis provides convergence rates comparable to those for corrupted models with Gaussian covariates and noise. 2) Online quantile regression: Importantly, our results relax the common assumption in prior work that the conditional density is continuous and provide a more fine-grained analysis for the moment bounds.",
        "arxiv_id": "2504.08178"
    },
    "2504.08277": {
        "SCORE": 16,
        "ARXIVID": "2504.08277",
        "COMMENT": "The paper introduces a novel method (mGNO) for physics-informed neural operators, which is foundational in AI for Science. It provides significant theoretical contributions by enabling exact gradients and improving generalization on irregular grids.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Ryan Y. Lin",
            "Julius Berner",
            "Valentin Duruisseaux",
            "David Pitt",
            "Daniel Leibovici",
            "Jean Kossaifi",
            "Kamyar Azizzadenesheli",
            "Anima Anandkumar"
        ],
        "title": "Enabling Automatic Differentiation with Mollified Graph Neural Operators",
        "abstract": "Physics-informed neural operators offer a powerful framework for learning solution operators of partial differential equations (PDEs) by combining data and physics losses. However, these physics losses rely on derivatives. Computing these derivatives remains challenging, with spectral and finite difference methods introducing approximation errors due to finite resolution. Here, we propose the mollified graph neural operator (mGNO), the first method to leverage automatic differentiation and compute \\emph{exact} gradients on arbitrary geometries. This enhancement enables efficient training on irregular grids and varying geometries while allowing seamless evaluation of physics losses at randomly sampled points for improved generalization. For a PDE example on regular grids, mGNO paired with autograd reduced the L2 relative data error by 20x compared to finite differences, although training was slower. It can also solve PDEs on unstructured point clouds seamlessly, using physics losses only, at resolutions vastly lower than those needed for finite differences to be accurate enough. On these unstructured point clouds, mGNO leads to errors that are consistently 2 orders of magnitude lower than machine learning baselines (Meta-PDE) for comparable runtimes, and also delivers speedups from 1 to 3 orders of magnitude compared to the numerical solver for similar accuracy. mGNOs can also be used to solve inverse design and shape optimization problems on complex geometries.",
        "arxiv_id": "2504.08277"
    },
    "2504.08051": {
        "SCORE": 16,
        "ARXIVID": "2504.08051",
        "COMMENT": "The paper introduces CGFlow, a novel framework for compositional generative flows in 3D molecular design. It aligns with foundational research in AI for Science, particularly in generative paradigms for molecular modeling.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Tony Shen",
            "Seonghwan Seo",
            "Ross Irwin",
            "Kieran Didi",
            "Simon Olsson",
            "Woo Youn Kim",
            "Martin Ester"
        ],
        "title": "Compositional Flows for 3D Molecule and Synthesis Pathway Co-design",
        "abstract": "Many generative applications, such as synthesis-based 3D molecular design, involve constructing compositional objects with continuous features. Here, we introduce Compositional Generative Flows (CGFlow), a novel framework that extends flow matching to generate objects in compositional steps while modeling continuous states. Our key insight is that modeling compositional state transitions can be formulated as a straightforward extension of the flow matching interpolation process. We further build upon the theoretical foundations of generative flow networks (GFlowNets), enabling reward-guided sampling of compositional structures. We apply CGFlow to synthesizable drug design by jointly designing the molecule's synthetic pathway with its 3D binding pose. Our approach achieves state-of-the-art binding affinity on all 15 targets from the LIT-PCBA benchmark, and 5.8$\\times$ improvement in sampling efficiency compared to 2D synthesis-based baseline. To our best knowledge, our method is also the first to achieve state of-art-performance in both Vina Dock (-9.38) and AiZynth success rate (62.2\\%) on the CrossDocked benchmark.",
        "arxiv_id": "2504.08051"
    },
    "2504.08415": {
        "SCORE": 16,
        "ARXIVID": "2504.08415",
        "COMMENT": "The paper proposes a novel hyperspherical representation method to enforce constraints in machine learning outputs, which aligns with foundational research in representation learning and model architecture.",
        "RELEVANCE": 8,
        "NOVELTY": 8,
        "authors": [
            "Gaetano Signorelli",
            "Michele Lombardi"
        ],
        "title": "Constrained Machine Learning Through Hyperspherical Representation",
        "abstract": "The problem of ensuring constraints satisfaction on the output of machine learning models is critical for many applications, especially in safety-critical domains. Modern approaches rely on penalty-based methods at training time, which do not guarantee to avoid constraints violations; or constraint-specific model architectures (e.g., for monotonocity); or on output projection, which requires to solve an optimization problem that might be computationally demanding. We present the Hypersherical Constrained Representation, a novel method to enforce constraints in the output space for convex and bounded feasibility regions (generalizable to star domains). Our method operates on a different representation system, where Euclidean coordinates are converted into hyperspherical coordinates relative to the constrained region, which can only inherently represent feasible points. Experiments on a synthetic and a real-world dataset show that our method has predictive performance comparable to the other approaches, can guarantee 100% constraint satisfaction, and has a minimal computational cost at inference time.",
        "arxiv_id": "2504.08415"
    },
    "2504.08112": {
        "SCORE": 15,
        "ARXIVID": "2504.08112",
        "COMMENT": "The paper investigates scaling laws for GNNs in atomistic materials modeling, which aligns with foundational research in AI for Science. It provides insights into scaling GNN architectures and dataset size effects.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Chaojian Li",
            "Zhifan Ye",
            "Massimiliano Lupo Pasini",
            "Jong Youl Choi",
            "Cheng Wan",
            "Yingyan Celine Lin",
            "Prasanna Balaprakash"
        ],
        "title": "Scaling Laws of Graph Neural Networks for Atomistic Materials Modeling",
        "abstract": "Atomistic materials modeling is a critical task with wide-ranging applications, from drug discovery to materials science, where accurate predictions of the target material property can lead to significant advancements in scientific discovery. Graph Neural Networks (GNNs) represent the state-of-the-art approach for modeling atomistic material data thanks to their capacity to capture complex relational structures. While machine learning performance has historically improved with larger models and datasets, GNNs for atomistic materials modeling remain relatively small compared to large language models (LLMs), which leverage billions of parameters and terabyte-scale datasets to achieve remarkable performance in their respective domains. To address this gap, we explore the scaling limits of GNNs for atomistic materials modeling by developing a foundational model with billions of parameters, trained on extensive datasets in terabyte-scale. Our approach incorporates techniques from LLM libraries to efficiently manage large-scale data and models, enabling both effective training and deployment of these large-scale GNN models. This work addresses three fundamental questions in scaling GNNs: the potential for scaling GNN model architectures, the effect of dataset size on model accuracy, and the applicability of LLM-inspired techniques to GNN architectures. Specifically, the outcomes of this study include (1) insights into the scaling laws for GNNs, highlighting the relationship between model size, dataset volume, and accuracy, (2) a foundational GNN model optimized for atomistic materials modeling, and (3) a GNN codebase enhanced with advanced LLM-based training techniques. Our findings lay the groundwork for large-scale GNNs with billions of parameters and terabyte-scale datasets, establishing a scalable pathway for future advancements in atomistic materials modeling.",
        "arxiv_id": "2504.08112"
    },
    "2504.08129": {
        "SCORE": 15,
        "ARXIVID": "2504.08129",
        "COMMENT": "The paper proposes a simpler linear time encoder for dynamic graph learning, which provides architectural insights and efficiency improvements, aligning with model architecture innovations.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Hsing-Huan Chung",
            "Shravan Chaudhari",
            "Xing Han",
            "Yoav Wald",
            "Suchi Saria",
            "Joydeep Ghosh"
        ],
        "title": "Between Linear and Sinusoidal: Rethinking the Time Encoder in Dynamic Graph Learning",
        "abstract": "Dynamic graph learning is essential for applications involving temporal networks and requires effective modeling of temporal relationships. Seminal attention-based models like TGAT and DyGFormer rely on sinusoidal time encoders to capture temporal relationships between edge events. In this paper, we study a simpler alternative: the linear time encoder, which avoids temporal information loss caused by sinusoidal functions and reduces the need for high dimensional time encoders. We show that the self-attention mechanism can effectively learn to compute time spans from linear time encodings and extract relevant temporal patterns. Through extensive experiments on six dynamic graph datasets, we demonstrate that the linear time encoder improves the performance of TGAT and DyGFormer in most cases. Moreover, the linear time encoder can lead to significant savings in model parameters with minimal performance loss. For example, compared to a 100-dimensional sinusoidal time encoder, TGAT with a 2-dimensional linear time encoder saves 43% of parameters and achieves higher average precision on five datasets. These results can be readily used to positively impact the design choices of a wide variety of dynamic graph learning architectures. The experimental code is available at: https://github.com/hsinghuan/dg-linear-time.git.",
        "arxiv_id": "2504.08129"
    },
    "2504.08377": {
        "SCORE": 15,
        "ARXIVID": "2504.08377",
        "COMMENT": "The paper introduces a model for explainable AI using certificates for reliable predictions, which aligns with foundational research in representation learning and theoretical insights.",
        "RELEVANCE": 8,
        "NOVELTY": 7,
        "authors": [
            "Avrim Blum",
            "Steve Hanneke",
            "Chirag Pabbaraju",
            "Donya Saless"
        ],
        "title": "Proofs as Explanations: Short Certificates for Reliable Predictions",
        "abstract": "We consider a model for explainable AI in which an explanation for a prediction $h(x)=y$ consists of a subset $S'$ of the training data (if it exists) such that all classifiers $h' \\in H$ that make at most $b$ mistakes on $S'$ predict $h'(x)=y$. Such a set $S'$ serves as a proof that $x$ indeed has label $y$ under the assumption that (1) the target function $h^\\star$ belongs to $H$, and (2) the set $S$ contains at most $b$ corrupted points. For example, if $b=0$ and $H$ is the family of linear classifiers in $\\mathbb{R}^d$, and if $x$ lies inside the convex hull of the positive data points in $S$ (and hence every consistent linear classifier labels $x$ as positive), then Carath\\'eodory's theorem states that $x$ lies inside the convex hull of $d+1$ of those points. So, a set $S'$ of size $d+1$ could be released as an explanation for a positive prediction, and would serve as a short proof of correctness of the prediction under the assumption of realizability.   In this work, we consider this problem more generally, for general hypothesis classes $H$ and general values $b\\geq 0$. We define the notion of the robust hollow star number of $H$ (which generalizes the standard hollow star number), and show that it precisely characterizes the worst-case size of the smallest certificate achievable, and analyze its size for natural classes. We also consider worst-case distributional bounds on certificate size, as well as distribution-dependent bounds that we show tightly control the sample size needed to get a certificate for any given test example. In particular, we define a notion of the certificate coefficient $\\varepsilon_x$ of an example $x$ with respect to a data distribution $D$ and target function $h^\\star$, and prove matching upper and lower bounds on sample size as a function of $\\varepsilon_x$, $b$, and the VC dimension $d$ of $H$.",
        "arxiv_id": "2504.08377"
    }
}